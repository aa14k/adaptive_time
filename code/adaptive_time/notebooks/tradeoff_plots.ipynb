{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of Trade-offs\n",
    "\n",
    "In this notebook we compare different time discretization methods. First, we collect\n",
    "a trajectory data from the environment at a fine discretization level (this is also\n",
    "the discretization level we run the policy at -- right now, anyway). Then we compare:\n",
    "\n",
    "1. Using uniform discretization at different granularities, e.g. updating with every\n",
    "    1st, 10th, 100th, ...? interactions.\n",
    "2. Using the adaptive method with different tolarances.\n",
    "\n",
    "In order to average out randomness, we'll repeat each setting 3 times for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from adaptive_time.features import Fourier_Features\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import adaptive_time.utils\n",
    "from adaptive_time import environments\n",
    "from adaptive_time import mc2\n",
    "from adaptive_time import samplers\n",
    "\n",
    "seed = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register(\n",
    "    id=\"CartPole-OURS-v0\",\n",
    "    entry_point=\"adaptive_time.environments.cartpole:CartPoleEnv\",\n",
    "    vector_entry_point=\"adaptive_time.environments.cartpole:CartPoleVectorEnv\",\n",
    "    max_episode_steps=500,\n",
    "    reward_threshold=475.0,\n",
    ")\n",
    "\n",
    "def reset_randomness(seed, env):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # env.seed(seed)\n",
    "    env.action_space.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We run the same environment and simple policy twice,\n",
      "with different time discretizations. The policy we use\n",
      "will always go left, so the time discretization does not\n",
      "make a difference to the behaviour, and the total return\n",
      "will be the same.\n",
      "\n",
      "Total undiscounted return:  10.589912009424973\n",
      "Total undiscounted return:  100.17508472458734\n",
      "\n",
      "We can expect some difference because we may get an extra\n",
      "timesteps in the more fine-grained discretization, but the\n",
      "difference should be smallish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayoub/adaptive_time/env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.stepTime to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.stepTime` for environment variables or `env.get_wrapper_attr('stepTime')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample usage of the environment.\n",
    "print(\n",
    "    \"We run the same environment and simple policy twice,\\n\"\n",
    "    \"with different time discretizations. The policy we use\\n\"\n",
    "    \"will always go left, so the time discretization does not\\n\"\n",
    "    \"make a difference to the behaviour, and the total return\\n\"\n",
    "    \"will be the same.\")\n",
    "print()\n",
    "\n",
    "policy = lambda obs: 0\n",
    "\n",
    "env = gym.make('CartPole-OURS-v0')\n",
    "tau = 0.02\n",
    "env.stepTime(tau)\n",
    "\n",
    "reset_randomness(seed, env)\n",
    "traj, early_term = environments.generate_trajectory(env, seed, policy)\n",
    "total_return_1 = sum(ts[2] for ts in traj)\n",
    "print(\"Total undiscounted return: \", total_return_1)\n",
    "\n",
    "env = gym.make('CartPole-OURS-v0')\n",
    "tau = 0.002\n",
    "env.stepTime(tau)\n",
    "\n",
    "reset_randomness(seed, env)\n",
    "traj, early_term = environments.generate_trajectory(env, seed, policy)\n",
    "total_return_2 = sum(ts[2] for ts in traj)\n",
    "print(\"Total undiscounted return: \", total_return_2)\n",
    "\n",
    "#np.testing.assert_almost_equal(total_return_1, total_return_2, decimal=0)\n",
    "\n",
    "print()\n",
    "print(\n",
    "    \"We can expect some difference because we may get an extra\\n\"\n",
    "    \"timesteps in the more fine-grained discretization, but the\\n\"\n",
    "    \"difference should be smallish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** you must adjust the discount factor if changing time-scales!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = Fourier_Features()\n",
    "phi.init_fourier_features(4,3)\n",
    "x_thres = 4.8\n",
    "theta_thres = 0.418\n",
    "phi.init_state_normalizers(\n",
    "    np.array([x_thres,2.0,theta_thres,1]),\n",
    "    np.array([-x_thres,-2.0,-theta_thres,-1]))\n",
    "phi.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(\n",
    "        seed, env, sampler, epsilon, num_episodes, gamma, tqdm=None, print_trajectory=False):\n",
    "    \"\"\"Returns the number of episodes it took to solve the environment.\"\"\"\n",
    "    if tqdm is None:\n",
    "        tqdm_use = lambda x: x\n",
    "    total_pivots = 0\n",
    "    total_interactions = 0\n",
    "\n",
    "    # We record:\n",
    "    returns_per_episode_q = np.zeros((2, num_episodes))\n",
    "    average_returns_q = np.zeros((2, num_episodes))  # the cumulative average of the above\n",
    "    predicted_returns_q = np.zeros((2, num_episodes))\n",
    "\n",
    "    reset_randomness(seed, env)\n",
    "\n",
    "    observation, _ = env.reset(seed=seed)\n",
    "    d = len(phi.get_fourier_feature(observation))\n",
    "    assert d == phi.num_parameters\n",
    "    features = np.identity(2 * d)   # An estimate of A = xx^T\n",
    "    targets = np.zeros(2 * d)  # An estimate of b = xG\n",
    "    weights = np.zeros(2 * d)   # The weights that approximate A^{-1} b\n",
    "\n",
    "    x_0 = phi.get_fourier_feature([0,0,0,0])  # the initial state\n",
    "    x_sa0 = mc2.phi_sa(x_0, 0)\n",
    "    x_sa1 = mc2.phi_sa(x_0, 1)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        def policy(state):\n",
    "            if random.random() < epsilon:\n",
    "                return env.action_space.sample()\n",
    "            # Otherwise calculate the best action.\n",
    "            x = phi.get_fourier_feature(state)\n",
    "            qs = np.zeros(2)\n",
    "            for action in [0, 1]:\n",
    "                x_sa = mc2.phi_sa(x, action)\n",
    "                qs[action] = np.inner(x_sa.flatten(), weights)\n",
    "            # adaptive_time.utils.softmax(qs, 1)\n",
    "            return adaptive_time.utils.argmax(qs)\n",
    "\n",
    "        trajectory, early_term = environments.generate_trajectory(env, policy=policy, max_steps=100_000)\n",
    "        if early_term:\n",
    "            #print(\"episode:\", episode)\n",
    "            #print(\"Did not drop it for a long time, returning!\")\n",
    "            return episode, total_pivots, total_interactions\n",
    "\n",
    "        total_interactions += len(trajectory)\n",
    "        print_trajectory = False\n",
    "        if print_trajectory:\n",
    "            print(\"trajectory-len: \", len(trajectory), \"; trajectory:\")\n",
    "            for idx, (o, a, r, o_) in enumerate(trajectory):\n",
    "                # * ignore reward, as it is always the same here.\n",
    "                # * o_ is the same as the next o.\n",
    "                print(f\"* {idx:4d}: o: {o}\\n\\t --> action: {a}\")\n",
    "\n",
    "        weights, targets, features, cur_avr_returns, num_pivots = mc2.ols_monte_carlo(\n",
    "            trajectory, sampler, tqdm_use, phi, weights, targets, features, x_0, gamma)\n",
    "        total_pivots += num_pivots\n",
    "        \n",
    "        # Store the empirical and predicted returns. For any episode, we may\n",
    "        # or may not have empirical returns for both actions. When we don't have an\n",
    "        # estimate, `nan` is returned.\n",
    "        returns_per_episode_q[:, episode] = cur_avr_returns\n",
    "        average_returns_q[:, episode] = np.nanmean(returns_per_episode_q[:, :episode+1], axis=1)\n",
    "\n",
    "        predicted_returns_q[0, episode] = np.inner(x_sa0.flatten(), weights)\n",
    "        predicted_returns_q[1, episode] = np.inner(x_sa1.flatten(), weights)\n",
    "        #print(\n",
    "        #    'episode:', episode,\n",
    "        #    ' empirical returns:' , returns_per_episode_q[:, episode],\n",
    "        #    ' predicted returns:' , predicted_returns_q[:, episode])\n",
    "    \n",
    "    return -1, total_pivots, total_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayoub/adaptive_time/env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.stepTime to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.stepTime` for environment variables or `env.get_wrapper_attr('stepTime')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50647faa90c24e3c99202868b7bebe7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0_1 <adaptive_time.samplers.AdaptiveQuadratureSampler2 object at 0x7fad1fb535e0>\n",
      "q0_05 <adaptive_time.samplers.AdaptiveQuadratureSampler2 object at 0x7fad1fb95c00>\n",
      "q0_005 <adaptive_time.samplers.AdaptiveQuadratureSampler2 object at 0x7fad1fb95690>\n",
      "q0_0 <adaptive_time.samplers.AdaptiveQuadratureSampler2 object at 0x7fad1fb960b0>\n",
      "u1 <adaptive_time.samplers.UniformSampler2 object at 0x7fad1fb96080>\n",
      "u5 <adaptive_time.samplers.UniformSampler2 object at 0x7fad1fb96530>\n",
      "u10 <adaptive_time.samplers.UniformSampler2 object at 0x7fad1fb96050>\n",
      "u20 <adaptive_time.samplers.UniformSampler2 object at 0x7fad1fb95ed0>\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 100\n",
    "epsilon = 0.0\n",
    "\n",
    "num_runs = 45\n",
    "\n",
    "tau = 0.002\n",
    "env.stepTime(tau)\n",
    "\n",
    "# tqdm_use = tqdm\n",
    "# tqdm_use = lambda x: x\n",
    "\n",
    "# sampler = samplers.AdaptiveQuadratureSampler2(tolerance=0.1)\n",
    "# sampler = samplers.AdaptiveQuadratureSampler2(tolerance=0.0)\n",
    "\n",
    "samplers_tried = dict(\n",
    "    q_20=samplers.AdaptiveQuadratureSampler2(tolerance=20)\n",
    "    q0_10=samplers.AdaptiveQuadratureSampler2(tolerance=10),\n",
    "    q0_5=samplers.AdaptiveQuadratureSampler2(tolerance=5),\n",
    "    q0_1=samplers.AdaptiveQuadratureSampler2(tolerance=1),\n",
    "    u5=samplers.UniformSampler2(5),\n",
    "    u10=samplers.UniformSampler2(10),\n",
    "    u20=samplers.UniformSampler2(20),\n",
    "    u40=samplers.UniformSampler2(40),\n",
    ")\n",
    "\n",
    "results = {}\n",
    "for name, sampler in tqdm(samplers_tried.items()):\n",
    "    print(name, sampler)\n",
    "    #results[name] = []\n",
    "    results[name] = Parallel(n_jobs = num_runs)(delayed(run_experiment)(seed+run, env, sampler, epsilon, num_episodes, gamma=0.999, tqdm=None) for run in range(num_runs))\n",
    "\n",
    "'''\n",
    "for name, sampler in samplers_tried.items():\n",
    "    results[name] = []\n",
    "    for run in range(num_runs):\n",
    "        print()\n",
    "        print(f\"=============      Running experiment with sampler {name}, run={run}     =============\")\n",
    "        results[name].append(\n",
    "            run_experiment(seed+run, env, sampler, epsilon, num_episodes, gamma=0.999, tqdm=None))\n",
    "'''\n",
    "print()\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results, a list of num_episodes, and a list of num_pivots for the different seeds:\n",
      "* q0_1\n",
      "    * num_episodes: ?? +- ??                full list: (1, -1, 8, -1, 6, -1, 1, 8, 4, -1, 1, 1, 1, 9, 5, -1, 1, -1, -1, 2, 7, 15, -1, -1, 1, 2, -1, -1, 4, 9, -1, 9, -1, 1, -1, -1, 1, 1, 2, 26, -1, 4, -1, 10, 18)\n",
      "    * num_pivots:   1678.31 +- 1084.09           full list: (16, 1748, 129, 1207, 91, 1321, 16, 127, 54, 1205, 16, 17, 22, 141, 70, 1752, 16, 1208, 2695, 29, 92, 237, 1589, 1204, 20, 73, 1207, 1448, 107, 157, 1409, 175, 1205, 17, 1207, 1204, 25, 16, 33, 319, 1713, 55, 49698, 129, 305)\n",
      "    * num_interactions:   15544.40 +- 4629.65           full list: (239, 71282, 1629, 12517, 1561, 13876, 227, 1749, 634, 12491, 212, 320, 423, 1732, 942, 25345, 255, 12559, 77138, 417, 1171, 2731, 104161, 12494, 401, 2352, 12517, 71608, 2630, 2416, 16762, 2194, 12482, 260, 12628, 12411, 755, 323, 477, 3480, 28442, 752, 154960, 1428, 4115)\n",
      "* q0_05\n",
      "    * num_episodes: ?? +- ??                full list: (4, -1, 51, 3, -1, -1, -1, 2, 2, 1, 1, 1, -1, 3, -1, -1, -1, -1, 4, 1, -1, 7, -1, -1, 1, -1, 1, 77, -1, 2, 2, 9, 1, -1, 5, 1, 1, 13, 2, -1, -1, 1, -1, -1, 20)\n",
      "    * num_pivots:   1450.09 +- 264.88           full list: (180, 3064, 2082, 70, 1813, 2406, 1808, 55, 44, 29, 24, 31, 7565, 71, 2054, 3098, 1810, 4415, 102, 29, 6705, 176, 3188, 1806, 32, 2798, 27, 1423, 2895, 63, 51, 617, 27, 2786, 109, 28, 61, 547, 570, 1948, 4554, 31, 1821, 1811, 430)\n",
      "    * num_interactions:   18270.87 +- 3990.07           full list: (4798, 65514, 28211, 598, 12532, 18850, 12404, 621, 372, 314, 212, 320, 85438, 552, 15258, 43055, 12432, 67230, 1142, 294, 42894, 1655, 102284, 12394, 401, 26284, 340, 61805, 26309, 645, 427, 5241, 305, 26391, 948, 234, 755, 4250, 4112, 13217, 92177, 383, 12596, 12479, 3516)\n",
      "* q0_005\n",
      "    * num_episodes: ?? +- ??                full list: (23, -1, 35, 1, 3, 47, 8, 60, 1, 1, 1, 1, 3, 6, -1, -1, -1, 6, -1, 1, 24, 5, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 10, 68, 1, 49, -1, 2, 9, -1, 1, -1, -1, 5)\n",
      "    * num_pivots:   4955.78 +- 2168.40           full list: (868, 2387, 804, 35, 86, 1075, 261, 1840, 36, 37, 32, 41, 90, 189, 7706, 5418, 8628, 1372, 7057, 33, 1437, 155, 3526, 30, 6503, 3185, 43, 2976, 4684, 9106, 2520, 32201, 37, 259, 4981, 32, 5392, 7497, 61, 237, 2559, 37, 95154, 2240, 163)\n",
      "    * num_interactions:   23417.84 +- 4616.69           full list: (6306, 25536, 4707, 340, 626, 6144, 1821, 13142, 249, 314, 212, 320, 669, 1268, 51562, 27068, 71642, 27687, 34235, 294, 10149, 1118, 24375, 217, 71649, 20329, 340, 71419, 30856, 61976, 15505, 100733, 305, 1517, 48234, 234, 30424, 72122, 395, 1461, 79737, 383, 122221, 12736, 1226)\n",
      "* q0_0\n",
      "    * num_episodes: ?? +- ??                full list: (2, -1, -1, 3, -1, 5, -1, -1, 1, 15, 2, 1, 55, -1, 8, -1, -1, -1, 1, 3, -1, -1, -1, 1, 1, 33, 1, -1, 98, -1, -1, -1, -1, -1, 1, 1, 14, -1, 48, 9, -1, -1, -1, 26, 3)\n",
      "    * num_pivots:   6844.58 +- 1314.22           full list: (112, 10550, 7974, 175, 6189, 736, 6636, 13619, 64, 1076, 415, 66, 9398, 8288, 460, 20736, 16578, 8991, 69, 140, 7333, 8281, 9074, 56, 86, 1594, 71, 5407, 4094, 10170, 8046, 7502, 30239, 7094, 89, 60, 1654, 46959, 14431, 475, 6529, 13749, 11219, 1351, 171)\n",
      "    * num_interactions:   28075.69 +- 5404.63           full list: (457, 41849, 22384, 686, 24325, 2110, 24104, 44947, 249, 4218, 1294, 320, 35564, 29863, 1613, 132477, 118612, 43865, 286, 548, 29850, 35572, 32344, 217, 401, 5317, 340, 18209, 12967, 36774, 26484, 31422, 94129, 40433, 352, 234, 10421, 159766, 38389, 1919, 76471, 50137, 26238, 4429, 820)\n",
      "* u1\n",
      "    * num_episodes: ?? +- ??                full list: (2, -1, 1, 1, 2, 10, 2, -1, 39, 1, 1, 9, 3, -1, 7, 9, 3, -1, 26, 2, 75, 1, -1, 1, 2, 2, 6, 19, 1, 5, 1, 6, -1, -1, 2, 1, 1, -1, 1, 1, -1, -1, -1, 2, 2)\n",
      "    * num_pivots:   4869.51 +- 1011.54           full list: (100, 12298, 60, 68, 96, 1738, 83, 12792, 2988, 63, 43, 395, 2009, 6951, 354, 17353, 11430, 8406, 3613, 84, 4316, 62, 8371, 44, 702, 131, 20306, 12674, 71, 679, 61, 673, 10882, 10054, 96, 47, 151, 15588, 55, 71, 23929, 6621, 22405, 86, 129)\n",
      "    * num_interactions:   24287.31 +- 5049.46           full list: (497, 61289, 296, 340, 477, 8669, 409, 63798, 14861, 314, 212, 1961, 10038, 34484, 1757, 86744, 57148, 41888, 18023, 417, 21430, 306, 41642, 217, 3505, 653, 101523, 63335, 351, 3384, 304, 3351, 54201, 50058, 475, 234, 755, 77725, 272, 354, 119438, 32911, 111818, 425, 640)\n",
      "* u5\n",
      "    * num_episodes: ?? +- ??                full list: (-1, 3, 12, -1, -1, 2, 1, 1, -1, 1, 1, 4, 5, -1, 11, 2, 8, 29, 2, 52, 4, 1, -1, 1, -1, 89, -1, -1, 5, 1, 3, -1, -1, -1, 2, 1, 6, 1, 1, -1, 3, -1, -1, 2, 3)\n",
      "    * num_pivots:   3344.13 +- 638.64           full list: (6552, 4937, 1418, 11414, 4046, 47, 23, 43, 6016, 32, 22, 104, 198, 14198, 396, 8472, 431, 3152, 45, 1977, 345, 31, 9661, 22, 1828, 13264, 14461, 8457, 124, 53, 608, 4037, 7213, 2583, 56, 24, 363, 33, 28, 5724, 6611, 2489, 8822, 44, 82)\n",
      "    * num_interactions:   33247.04 +- 6362.50           full list: (65052, 49358, 14146, 113628, 39912, 461, 227, 430, 59578, 314, 212, 1023, 1967, 141559, 3912, 84709, 4274, 31370, 444, 19536, 3430, 306, 96011, 217, 17776, 132239, 144181, 84041, 1208, 522, 6069, 39954, 71655, 24977, 551, 234, 3611, 323, 272, 56831, 66104, 24656, 87610, 425, 802)\n",
      "* u10\n",
      "    * num_episodes: ?? +- ??                full list: (1, -1, 1, 10, -1, 2, 1, 2, -1, 1, -1, 1, 26, 1, -1, -1, -1, 3, 3, -1, 8, -1, -1, 1, 3, 4, 30, -1, 7, 3, 3, 2, 14, 1, 21, 1, 2, -1, 1, -1, -1, 1, -1, 2, 9)\n",
      "    * num_pivots:   1297.24 +- 262.55           full list: (12, 2443, 15, 125, 1760, 24, 12, 35, 2440, 16, 2195, 16, 1081, 16, 791, 4861, 1574, 1442, 128, 1542, 163, 3114, 6005, 11, 52, 64, 5085, 4029, 591, 54, 47, 27, 238, 13, 1487, 12, 65, 5741, 14, 1957, 4463, 20, 3931, 23, 642)\n",
      "    * num_interactions:   25554.76 +- 5200.98           full list: (239, 48130, 296, 2431, 34329, 461, 227, 678, 47374, 314, 42394, 320, 21349, 302, 14354, 96327, 30091, 28806, 2535, 29750, 3178, 61301, 119226, 217, 995, 1237, 101394, 79494, 11749, 1044, 899, 508, 4667, 260, 29539, 234, 1294, 113826, 272, 38257, 88168, 383, 77939, 426, 12750)\n",
      "* u20\n",
      "    * num_episodes: ?? +- ??                full list: (-1, 4, 1, 1, -1, 16, -1, -1, 2, -1, 1, 4, 1, -1, 7, 37, 5, -1, 1, 4, -1, 2, 95, 1, 1, -1, 1, -1, -1, 2, 8, 2, 2, 2, -1, 3, 1, -1, -1, 2, -1, 1, -1, 3, 1)\n",
      "    * num_pivots:   727.33 +- 175.08           full list: (505, 1240, 8, 9, 790, 707, 402, 1073, 11, 1068, 6, 26, 11, 1005, 121, 2159, 39, 2315, 8, 62, 996, 12, 3387, 6, 11, 3218, 9, 1394, 815, 18, 235, 14, 13, 12, 855, 19, 19, 413, 403, 13, 4524, 10, 4737, 19, 13)\n",
      "    * num_interactions:   28150.96 +- 6905.73           full list: (18655, 49488, 296, 340, 29621, 27936, 12404, 39931, 372, 41126, 212, 948, 423, 38166, 4710, 85590, 1475, 90403, 286, 2348, 37333, 462, 132774, 217, 401, 126422, 340, 53500, 31357, 645, 9269, 509, 477, 430, 30882, 683, 755, 13731, 13618, 477, 178990, 383, 187204, 687, 517)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print()\n",
    "print(\"Results, a list of num_episodes, and a list of num_pivots for the different seeds:\")\n",
    "for name, sub_results in results.items():\n",
    "    num_episodes, num_pivots, num_interactions = zip(*sub_results)\n",
    "    print(f\"* {name}\")\n",
    "    if -1 in num_episodes:\n",
    "        num_eps_stats = f\"?? +- ??\"\n",
    "    else:\n",
    "        mean_num_episodes = np.mean(num_episodes)\n",
    "        std_err_episodes = np.std(num_episodes) / np.sqrt(len(num_episodes))\n",
    "        num_eps_stats = f\"{np.mean(num_episodes):.2f} +- {std_err_episodes:.2f}\"\n",
    "\n",
    "    std_err_pivots = np.std(num_pivots) / np.sqrt(len(num_pivots))\n",
    "    std_err_num_interactions = np.std(num_interactions) / np.sqrt(len(num_interactions))\n",
    "    print(f\"    * num_episodes: {num_eps_stats}                full list: {num_episodes}\")\n",
    "    print(f\"    * num_pivots:   {np.mean(num_pivots):.2f} +- {std_err_pivots:.2f}           full list: {num_pivots}\")\n",
    "    print(f\"    * num_interactions:   {np.mean(num_interactions):.2f} +- {std_err_num_interactions:.2f}\"\n",
    "          f\"           full list: {num_interactions}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
