{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of Trade-offs\n",
    "\n",
    "In this notebook we compare different time discretization methods. First, we collect\n",
    "a trajectory data from the environment at a fine discretization level (this is also\n",
    "the discretization level we run the policy at -- right now, anyway). Then we compare:\n",
    "\n",
    "1. Using uniform discretization at different granularities, e.g. updating with every\n",
    "    1st, 10th, 100th, ...? interactions.\n",
    "2. Using the adaptive method with different tolarances.\n",
    "\n",
    "In order to average out randomness, we'll repeat each setting 3 times for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from adaptive_time.features import Fourier_Features\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import adaptive_time.utils\n",
    "from adaptive_time import environments\n",
    "from adaptive_time import mc2\n",
    "from adaptive_time import samplers\n",
    "\n",
    "seed = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register(\n",
    "    id=\"CartPole-OURS-v0\",\n",
    "    entry_point=\"adaptive_time.environments.cartpole:CartPoleEnv\",\n",
    "    vector_entry_point=\"adaptive_time.environments.cartpole:CartPoleVectorEnv\",\n",
    "    max_episode_steps=500,\n",
    "    reward_threshold=475.0,\n",
    ")\n",
    "\n",
    "def reset_randomness(seed, env):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # env.seed(seed)\n",
    "    env.action_space.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We run the same environment and simple policy twice,\n",
      "with different time discretizations. The policy we use\n",
      "will always go left, so the time discretization does not\n",
      "make a difference to the behaviour, and the total return\n",
      "will be the same.\n",
      "\n",
      "Total undiscounted return:  10.589912009424973\n",
      "Total undiscounted return:  10.017508472458736\n",
      "\n",
      "We can expect some difference because we may get an extra\n",
      "timesteps in the more fine-grained discretization, but the\n",
      "difference should be smallish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szepi1991/Code/adaptive_time/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.stepTime to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.stepTime` for environment variables or `env.get_wrapper_attr('stepTime')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample usage of the environment.\n",
    "print(\n",
    "    \"We run the same environment and simple policy twice,\\n\"\n",
    "    \"with different time discretizations. The policy we use\\n\"\n",
    "    \"will always go left, so the time discretization does not\\n\"\n",
    "    \"make a difference to the behaviour, and the total return\\n\"\n",
    "    \"will be the same.\")\n",
    "print()\n",
    "\n",
    "policy = lambda obs: 0\n",
    "\n",
    "env = gym.make('CartPole-OURS-v0')\n",
    "tau = 0.02\n",
    "env.stepTime(tau)\n",
    "\n",
    "reset_randomness(seed, env)\n",
    "traj = environments.generate_trajectory(env, seed, policy)\n",
    "total_return_1 = sum(ts[2] for ts in traj)\n",
    "print(\"Total undiscounted return: \", total_return_1)\n",
    "\n",
    "env = gym.make('CartPole-OURS-v0')\n",
    "tau = 0.002\n",
    "env.stepTime(tau)\n",
    "\n",
    "reset_randomness(seed, env)\n",
    "traj = environments.generate_trajectory(env, seed, policy)\n",
    "total_return_2 = sum(ts[2] for ts in traj)\n",
    "print(\"Total undiscounted return: \", total_return_2)\n",
    "\n",
    "np.testing.assert_almost_equal(total_return_1, total_return_2, decimal=0)\n",
    "\n",
    "print()\n",
    "print(\n",
    "    \"We can expect some difference because we may get an extra\\n\"\n",
    "    \"timesteps in the more fine-grained discretization, but the\\n\"\n",
    "    \"difference should be smallish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** you must adjust the discount factor if changing time-scales!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = Fourier_Features()\n",
    "phi.init_fourier_features(4,4)\n",
    "x_thres = 4.8\n",
    "theta_thres = 0.418\n",
    "phi.init_state_normalizers(np.array([x_thres,2.0,theta_thres,1]), np.array([-x_thres,-2.0,-theta_thres,-1]))\n",
    "phi.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 548/548 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szepi1991/Code/adaptive_time/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.stepTime to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.stepTime` for environment variables or `env.get_wrapper_attr('stepTime')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e7bc29975c47dd9e0072de5a1bd3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0  empirical returns: [39.07399847  0.        ]  predicted returns: [35.91830993 30.24942918]\n",
      "Using 361/361 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d547004f44e243a9aa6d672af150ee23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1  empirical returns: [28.45849011  0.        ]  predicted returns: [35.36472805 35.71637349]\n",
      "Using 1863/1863 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fb4054af914f6fbf6ef4589eb58d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2  empirical returns: [ 0.         82.02244811]  predicted returns: [54.30500398 66.10999344]\n",
      "Using 649/649 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb89fe79bbc47bc92a7fe1700cbb315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/649 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3  empirical returns: [ 0.         44.88951313]  predicted returns: [41.19728746 47.10703236]\n",
      "Using 255/255 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7ac63e9734471282ef14dc54a538de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4  empirical returns: [ 0.         19.43532548]  predicted returns: [46.67649866 50.50184754]\n",
      "Using 233/233 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72376a4f979e4614b6137b99778b3345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5  empirical returns: [ 0.         18.79206236]  predicted returns: [32.47099161 37.37620204]\n",
      "Using 455/455 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3dd5ddb0ca411abf778151901b1fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/455 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6  empirical returns: [ 0.         33.11931168]  predicted returns: [32.07258811 34.39966632]\n",
      "Using 340/340 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7b4963431e4ef2ab025d7026594f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7  empirical returns: [ 0.         26.68285605]  predicted returns: [30.02010511 32.90284232]\n",
      "Using 403/403 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b50e03bf19a484f8cb8563906b2da42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 8  empirical returns: [ 0.         31.01961097]  predicted returns: [31.835958   34.61759991]\n",
      "Using 675/675 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b102ec9d194a4b96ea55f0b9bc80f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 9  empirical returns: [ 0.         46.77211508]  predicted returns: [31.60788984 35.15722459]\n",
      "Using 534/534 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5293d63f534b59a4514050236a019f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10  empirical returns: [ 0.        37.8610709]  predicted returns: [32.52375828 35.68179701]\n",
      "Using 611/611 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5545a29e79496c90fde76568fd2ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 11  empirical returns: [ 0.         41.61848623]  predicted returns: [32.58748281 36.25691349]\n",
      "Using 611/611 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1aa46b972f4328a94218a16ecf9022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 12  empirical returns: [ 0.         41.81897408]  predicted returns: [33.02158675 36.83651904]\n",
      "Using 609/609 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8d5c0ed22e48358748a94c62f3302c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/609 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 13  empirical returns: [ 0.         41.43381738]  predicted returns: [33.18877555 37.00971386]\n",
      "Using 615/615 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ad58e21f1745599df4a7394b59d97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/615 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 14  empirical returns: [ 0.         41.70953441]  predicted returns: [33.35995812 37.10163755]\n",
      "Using 620/620 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822f9f53a63e4df5aa8bc0e24dae559c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 15  empirical returns: [ 0.         41.84819395]  predicted returns: [33.60520272 37.21336416]\n",
      "Using 627/629 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91489e8d504a4fd286bb1f8f97949567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 16  empirical returns: [ 0.         42.15698783]  predicted returns: [33.75531849 37.32372441]\n",
      "Using 782/782 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb990b61c6094488a5984db04bbdf3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 17  empirical returns: [ 0.         51.24447541]  predicted returns: [34.32819605 38.53884562]\n",
      "Using 738/738 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bdfa1b76894bc7b0332b0cb10b063c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/738 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 18  empirical returns: [ 0.         48.89151119]  predicted returns: [35.03648163 39.41646117]\n",
      "Using 687/687 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96c1b1f1416470eb65143a7f0bc8338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 19  empirical returns: [ 0.         46.17854184]  predicted returns: [35.35472344 39.830005  ]\n",
      "Using 702/702 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4314cf42cba4fffb7563d93ae9965a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 20  empirical returns: [ 0.         46.83524623]  predicted returns: [35.6786645  40.20209902]\n",
      "Using 729/729 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300228aa3bd640148434b7fb6a6a76ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 21  empirical returns: [48.16442451  0.        ]  predicted returns: [36.19727177 40.67224795]\n",
      "Using 750/750 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b933bfb7fcb4bd7b55e4fe4958205de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 22  empirical returns: [ 0.         49.14948636]  predicted returns: [36.60079675 41.09670042]\n",
      "Using 763/763 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431dff23f146417e929535f6644e6288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 23  empirical returns: [ 0.         50.06394522]  predicted returns: [37.0519421  41.56123152]\n",
      "Did 5000 steps! 5000\n",
      "Did 5000 steps! 10000\n",
      "Did 5000 steps! 15000\n",
      "Did 5000 steps! 20000\n",
      "Did 5000 steps! 25000\n",
      "Did 5000 steps! 30000\n",
      "Did 5000 steps! 35000\n",
      "Did 5000 steps! 40000\n",
      "Did 5000 steps! 45000\n",
      "Did 5000 steps! 50000\n",
      "Did 5000 steps! 55000\n",
      "Did 5000 steps! 60000\n",
      "Did 5000 steps! 65000\n",
      "Did 5000 steps! 70000\n",
      "Did 5000 steps! 75000\n",
      "Did 5000 steps! 80000\n",
      "Did 5000 steps! 85000\n",
      "Did 5000 steps! 90000\n",
      "Did 5000 steps! 95000\n",
      "Did 5000 steps! 100000\n",
      "Did 5000 steps! 105000\n",
      "Did 5000 steps! 110000\n",
      "Did 5000 steps! 115000\n",
      "Did 5000 steps! 120000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# adaptive_time.utils.softmax(qs, 1)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m adaptive_time\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39margmax(qs)\n\u001b[0;32m---> 46\u001b[0m trajectory \u001b[38;5;241m=\u001b[39m \u001b[43menvironments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_trajectory:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrajectory-len: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trajectory), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m; trajectory:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Code/adaptive_time/code/adaptive_time/environments/__init__.py:63\u001b[0m, in \u001b[0;36mgenerate_trajectory\u001b[0;34m(env, seed, policy, termination_prob)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m terminated:\n\u001b[1;32m     62\u001b[0m     steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 63\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     observation_, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     65\u001b[0m     trajectory\u001b[38;5;241m.\u001b[39mappend([observation, action, reward, observation_])\n",
      "Cell \u001b[0;32mIn[5], line 42\u001b[0m, in \u001b[0;36mpolicy\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     41\u001b[0m     x_sa \u001b[38;5;241m=\u001b[39m mc2\u001b[38;5;241m.\u001b[39mphi_sa(x, action)\n\u001b[0;32m---> 42\u001b[0m     qs[action] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minner(x_sa\u001b[38;5;241m.\u001b[39mflatten(), weights)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# adaptive_time.utils.softmax(qs, 1)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adaptive_time\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39margmax(qs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_trajectory = False\n",
    "gamma = 0.999\n",
    "\n",
    "num_episodes = 500\n",
    "epsilon = 0.1\n",
    "\n",
    "tau = 0.002\n",
    "env.stepTime(tau)\n",
    "\n",
    "sampler = samplers.AdaptiveQuadratureSampler2(tolerance=0.1)\n",
    "# sampler = samplers.AdaptiveQuadratureSampler2(tolerance=0.0)\n",
    "\n",
    "\n",
    "# We record:\n",
    "returns_per_episode_q = np.zeros((2, num_episodes))\n",
    "average_returns_q = np.zeros((2, num_episodes))  # the cumulative average of the above\n",
    "predicted_returns_q = np.zeros((2, num_episodes))\n",
    "\n",
    "reset_randomness(seed, env)\n",
    "\n",
    "observation, _ = env.reset(seed=seed)\n",
    "d = len(phi.get_fourier_feature(observation))\n",
    "assert d == phi.num_parameters\n",
    "features = np.identity(2 * d)   # An estimate of A = xx^T\n",
    "targets = np.zeros(2 * d)  # An estimate of b = xG\n",
    "weights = np.zeros(2 * d)   # The weights that approximate A^{-1} b\n",
    "\n",
    "x_0 = phi.get_fourier_feature([0,0,0,0])  # the initial state\n",
    "x_sa0 = mc2.phi_sa(x_0, 0)\n",
    "x_sa1 = mc2.phi_sa(x_0, 1)\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    def policy(state):\n",
    "        if random.random() < epsilon:\n",
    "            return env.action_space.sample()\n",
    "        # Otherwise calculate the best action.\n",
    "        x = phi.get_fourier_feature(state)\n",
    "        qs = np.zeros(2)\n",
    "        for action in [0, 1]:\n",
    "            x_sa = mc2.phi_sa(x, action)\n",
    "            qs[action] = np.inner(x_sa.flatten(), weights)\n",
    "        # adaptive_time.utils.softmax(qs, 1)\n",
    "        return adaptive_time.utils.argmax(qs)\n",
    "\n",
    "    trajectory = environments.generate_trajectory(env, policy=policy)\n",
    "\n",
    "    if print_trajectory:\n",
    "        print(\"trajectory-len: \", len(trajectory), \"; trajectory:\")\n",
    "        for idx, (o, a, r, o_) in enumerate(trajectory):\n",
    "            # * ignore reward, as it is always the same here.\n",
    "            # * o_ is the same as the next o.\n",
    "            print(f\"* {idx:4d}: o: {o}\\n\\t --> action: {a}\")\n",
    "\n",
    "    weights, targets, features, cur_avr_returns = mc2.ols_monte_carlo(\n",
    "        trajectory, sampler, tqdm, phi, weights, targets, features, x_0, gamma)\n",
    "    \n",
    "    # Store the empirical and predicted returns. For any episode, we may\n",
    "    # or may not have empirical returns for both actions. When we don't have an\n",
    "    # estimate, `nan` is returned.\n",
    "    returns_per_episode_q[:, episode] = cur_avr_returns\n",
    "    average_returns_q[:, episode] = np.nanmean(returns_per_episode_q[:, :episode+1], axis=1)\n",
    "\n",
    "    predicted_returns_q[0, episode] = np.inner(x_sa0.flatten(), weights)\n",
    "    predicted_returns_q[1, episode] = np.inner(x_sa1.flatten(), weights)\n",
    "    print(\n",
    "        'episode:', episode,\n",
    "        ' empirical returns:' , returns_per_episode_q[:, episode],\n",
    "        ' predicted returns:' , predicted_returns_q[:, episode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
