{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from adaptive_time.utils import set_directory_in_project\n",
    "\n",
    "from importlib import reload\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_time import plot_utils\n",
    "from adaptive_time import utils\n",
    "from adaptive_time import run_lib\n",
    "from adaptive_time import value_est\n",
    "from adaptive_time.value_est import approx_integrators\n",
    "\n",
    "approx_integrators = reload(approx_integrators)\n",
    "run_lib = reload(run_lib)\n",
    "value_est = reload(value_est)\n",
    "plot_utils = reload(plot_utils)\n",
    "utils = reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to /Users/chanb/research/ualberta/adaptive_time\n",
      "['inverted_double_pendulum-v2', 'swimmer-v3', 'hopper-v3', 'ant-v3', 'cheetah-v3', 'pusher-v2']\n"
     ]
    }
   ],
   "source": [
    "set_directory_in_project()\n",
    "data_dir = \"./data\"\n",
    "env_names = [env_name for env_name in os.listdir(data_dir) if not env_name.startswith(\".DS_Store\")]\n",
    "print(env_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers_tried = dict(\n",
    "    q100=approx_integrators.AdaptiveQuadratureIntegrator(tolerance=100),\n",
    "    q10=approx_integrators.AdaptiveQuadratureIntegrator(tolerance=10),\n",
    "    q1=approx_integrators.AdaptiveQuadratureIntegrator(tolerance=1),\n",
    "    q0=approx_integrators.AdaptiveQuadratureIntegrator(tolerance=0),\n",
    "    u1=approx_integrators.UniformlySpacedIntegrator(1),\n",
    "    u10=approx_integrators.UniformlySpacedIntegrator(50),\n",
    "    u500=approx_integrators.UniformlySpacedIntegrator(500),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_approx_integrals(\n",
    "    reward_file: str,\n",
    "    samplers_tried: dict,\n",
    "):\n",
    "    print(reward_file)\n",
    "    reward_sequences = np.load(reward_file).T\n",
    "    idxes = np.where(reward_sequences[:, 0][:, None] - reward_sequences[:, 0][None, :] == 0)\n",
    "    \n",
    "    if len(idxes[0]) == len(idxes[1]):\n",
    "        assert np.sum(idxes[0] - idxes[1]) == 0\n",
    "    else:\n",
    "        assert 0\n",
    "\n",
    "    approx_integrals = {}\n",
    "    num_pivots = {}\n",
    "    for sampler_name, sampler in samplers_tried.items():\n",
    "        approx_integrals[sampler_name] = []\n",
    "        num_pivots[sampler_name] = []\n",
    "        for idx, reward_seq in enumerate(reward_sequences):\n",
    "            integral, all_pivots = sampler.integrate(reward_seq)\n",
    "            approx_integrals[sampler_name].append(integral)\n",
    "            num_pivots[sampler_name].append(len(all_pivots))\n",
    "        approx_integrals[sampler_name] = np.array(approx_integrals[sampler_name])\n",
    "        num_pivots[sampler_name] = np.array(num_pivots[sampler_name])\n",
    "\n",
    "    return {\n",
    "        \"reward_file\": np.array([reward_file]),\n",
    "        \"approx_integrals\": approx_integrals,\n",
    "        \"num_pivots\": num_pivots,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba41a4844d56449ab32b328299af7dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: inverted_double_pendulum-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_9.npy\n",
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_8.npy\n",
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_7.npy\n",
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_6.npy\n",
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_5.npy\n",
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_4.npy\n",
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_0.npy\n",
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_1.npy\n",
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_3.npy\n",
      "./data/inverted_double_pendulum-v2/Rewards_50000_1000_2.npy\n",
      "env: swimmer-v3\n",
      "./data/swimmer-v3/Rewards_40000_1000_8.npy\n",
      "./data/swimmer-v3/Rewards_40000_1000_9.npy\n",
      "./data/swimmer-v3/Rewards_40000_1000_2.npy\n",
      "./data/swimmer-v3/Rewards_40000_1000_3.npy\n",
      "./data/swimmer-v3/Rewards_40000_1000_1.npy\n",
      "./data/swimmer-v3/Rewards_40000_1000_0.npy\n",
      "./data/swimmer-v3/Rewards_40000_1000_4.npy\n",
      "./data/swimmer-v3/Rewards_40000_1000_5.npy\n",
      "./data/swimmer-v3/Rewards_40000_1000_7.npy\n",
      "./data/swimmer-v3/Rewards_40000_1000_6.npy\n",
      "env: hopper-v3\n",
      "./data/hopper-v3/Rewards_50000_1000_9.npy\n",
      "./data/hopper-v3/Rewards_50000_1000_8.npy\n",
      "./data/hopper-v3/Rewards_50000_1000_6.npy\n",
      "./data/hopper-v3/Rewards_50000_1000_7.npy\n",
      "./data/hopper-v3/Rewards_50000_1000_5.npy\n",
      "./data/hopper-v3/Rewards_50000_1000_4.npy\n",
      "./data/hopper-v3/Rewards_50000_1000_0.npy\n",
      "./data/hopper-v3/Rewards_50000_1000_1.npy\n",
      "./data/hopper-v3/Rewards_50000_1000_3.npy\n",
      "./data/hopper-v3/Rewards_50000_1000_2.npy\n",
      "env: ant-v3\n",
      "./data/ant-v3/Rewards_50000_1000_9.npy\n",
      "./data/ant-v3/Rewards_50000_1000_8.npy\n",
      "./data/ant-v3/Rewards_50000_1000_6.npy\n",
      "./data/ant-v3/Rewards_50000_1000_7.npy\n",
      "./data/ant-v3/Rewards_50000_1000_5.npy\n",
      "./data/ant-v3/Rewards_50000_1000_4.npy\n",
      "./data/ant-v3/Rewards_50000_1000_0.npy\n",
      "./data/ant-v3/Rewards_50000_1000_1.npy\n",
      "./data/ant-v3/Rewards_50000_1000_3.npy\n",
      "./data/ant-v3/Rewards_50000_1000_2.npy\n",
      "env: cheetah-v3\n",
      "./data/cheetah-v3/Rewards_50000_1000_9.npy\n",
      "./data/cheetah-v3/Rewards_50000_1000_8.npy\n",
      "./data/cheetah-v3/Rewards_50000_1000_6.npy\n",
      "./data/cheetah-v3/Rewards_50000_1000_7.npy\n",
      "./data/cheetah-v3/Rewards_50000_1000_5.npy\n",
      "./data/cheetah-v3/Rewards_50000_1000_4.npy\n",
      "./data/cheetah-v3/Rewards_50000_1000_0.npy\n",
      "./data/cheetah-v3/Rewards_50000_1000_1.npy\n",
      "./data/cheetah-v3/Rewards_50000_1000_3.npy\n",
      "./data/cheetah-v3/Rewards_50000_1000_2.npy\n",
      "env: pusher-v2\n",
      "./data/pusher-v2/Rewards_50000_1000_9.npy\n",
      "./data/pusher-v2/Rewards_50000_1000_8.npy\n",
      "./data/pusher-v2/Rewards_50000_1000_6.npy\n",
      "./data/pusher-v2/Rewards_50000_1000_7.npy\n",
      "./data/pusher-v2/Rewards_50000_1000_5.npy\n",
      "./data/pusher-v2/Rewards_50000_1000_4.npy\n",
      "./data/pusher-v2/Rewards_50000_1000_0.npy\n",
      "./data/pusher-v2/Rewards_50000_1000_1.npy\n",
      "./data/pusher-v2/Rewards_50000_1000_3.npy\n",
      "./data/pusher-v2/Rewards_50000_1000_2.npy\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"./mujoco_val_est.pkl\"\n",
    "if not os.path.isfile(checkpoint):\n",
    "    for env_name in tqdm(env_names):\n",
    "        if env_name in all_results:\n",
    "            continue\n",
    "        print(\"env: {}\".format(env_name))\n",
    "\n",
    "        env_dir = os.path.join(data_dir, env_name)\n",
    "        all_results.setdefault(env_name, {})\n",
    "        run_files = [run_file for run_file in os.listdir(env_dir) if not run_file.startswith(\".DS_Store\")]\n",
    "        all_results[env_name] = Parallel(\n",
    "            n_jobs=len(run_files)\n",
    "        )(\n",
    "            delayed(compute_approx_integrals)(\n",
    "                os.path.join(env_dir, run_file),\n",
    "                samplers_tried,\n",
    "            )\n",
    "            for run_file in run_files\n",
    "        )\n",
    "    pickle.dump(all_results, open(checkpoint, \"wb\"))\n",
    "else:\n",
    "    all_results = pickle.load(open(checkpoint, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agg_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     env_name: jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: np\u001b[38;5;241m.\u001b[39mconcatenate(args),\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m*\u001b[39mall_results[env_name]\n\u001b[1;32m      5\u001b[0m     ) \u001b[38;5;28;01mfor\u001b[39;00m env_name \u001b[38;5;129;01min\u001b[39;00m all_results\n\u001b[1;32m      6\u001b[0m }\n",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m agg_results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     env_name: \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m env_name \u001b[38;5;129;01min\u001b[39;00m all_results\n\u001b[1;32m      6\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/adaptive_time/lib/python3.10/site-packages/jax/_src/tree_util.py:312\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    310\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    311\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_leaves\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/adaptive_time/lib/python3.10/site-packages/jax/_src/tree_util.py:312\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    310\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    311\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m      1\u001b[0m agg_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     env_name: jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m*\u001b[39mall_results[env_name]\n\u001b[1;32m      5\u001b[0m     ) \u001b[38;5;28;01mfor\u001b[39;00m env_name \u001b[38;5;129;01min\u001b[39;00m all_results\n\u001b[1;32m      6\u001b[0m }\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "agg_results = {\n",
    "    env_name: jax.tree_util.tree_map(\n",
    "        lambda *args: np.concatenate(args),\n",
    "        *all_results[env_name]\n",
    "    ) for env_name in all_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_checkpoint = \"./combined_mujoco_val_est.pkl\"\n",
    "pickle.dump(agg_results, open(combined_checkpoint, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results[\"ant-v3\"][\"approx_integrals\"][\"q100\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_budget = 10_000_000\n",
    "sample_block = 1_000_000\n",
    "\n",
    "est_results = {}\n",
    "num_seeds = 10\n",
    "\n",
    "for env_name in agg_results:\n",
    "    print(env_name)\n",
    "    vals_per_state = np.concatenate(\n",
    "        [np.sum(np.load(reward_file), axis=-1) for reward_file in agg_results[env_name][\"reward_file\"]]\n",
    "    )\n",
    "    print(vals_per_state.shape)\n",
    "\n",
    "    approx_integrals = agg_results[env_name][\"approx_integrals\"]\n",
    "    num_pivots = agg_results[env_name][\"num_pivots\"]\n",
    "\n",
    "    weights = np.ones(len(vals_per_state)) / len(vals_per_state)\n",
    "    true_value = np.sum(weights * vals_per_state)\n",
    "\n",
    "    est_results[env_name] = {\n",
    "        \"weights\": weights,\n",
    "        \"true_value\": true_value,\n",
    "        \"runs\": []\n",
    "    }\n",
    "\n",
    "    for seed in tqdm(range(num_seeds)):\n",
    "        estimated_values_by_episode = {}\n",
    "        number_of_pivots_by_episode = {}\n",
    "        all_values_by_episode = {}\n",
    "\n",
    "        rng = np.random.RandomState(seed)\n",
    "        start_states = rng.choice(len(vals_per_state), p=weights, size=(update_budget))\n",
    "\n",
    "        for sampler_name, sampler in samplers_tried.items():\n",
    "            # print(\"sampler_name:\", sampler_name)\n",
    "            # Update the value estimate with new samples until we run out of budget.\n",
    "            used_updates = 0\n",
    "            value_estimate = 0\n",
    "            num_episodes = 0\n",
    "            all_values_by_episode[sampler_name] = []\n",
    "\n",
    "            estimated_values_by_episode[sampler_name] = []\n",
    "            number_of_pivots_by_episode[sampler_name] = []\n",
    "\n",
    "            # pbar = tqdm(total = update_budget)\n",
    "            while used_updates < update_budget:\n",
    "                num_episodes += 1\n",
    "                if num_episodes % sample_block == 0:\n",
    "                    start_states = rng.choice(len(vals_per_state), p=weights, size=(update_budget))\n",
    "                start_state = start_states[(num_episodes - 1) % sample_block]\n",
    "                val_sample = approx_integrals[sampler_name][start_state]\n",
    "                all_values_by_episode[sampler_name].append(val_sample)\n",
    "                \n",
    "                value_estimate += (1.0/num_episodes) * (val_sample - value_estimate)\n",
    "                used_updates += num_pivots[sampler_name][start_state]\n",
    "\n",
    "                estimated_values_by_episode[sampler_name].append(value_estimate)\n",
    "                number_of_pivots_by_episode[sampler_name].append(used_updates)\n",
    "            #     pbar.update(num_pivots[sampler_name][start_state])\n",
    "            # pbar.close()\n",
    "        est_results[env_name][\"runs\"].append({\n",
    "            \"estimated_values_by_episode\": estimated_values_by_episode,\n",
    "            \"number_of_pivots_by_episode\": number_of_pivots_by_episode,\n",
    "            \"all_values_by_episode\": all_values_by_episode,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_checkpoint = \"./estimator_mujoco_val_est.pkl\"\n",
    "pickle.dump(est_results, open(estimator_checkpoint, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify final means.\n",
    "for key, value in estimated_values_by_episode.items():\n",
    "    mean_total = np.mean(all_values_by_episode[key])\n",
    "    mean_updated = value[-1]\n",
    "    print(\"sampler:\", key, \"mean_total:\", mean_total, \"mean_updated:\", mean_updated)\n",
    "    if abs(mean_total - mean_updated) > 0.01:\n",
    "        assert False, f\"Means don't match for {key}: {mean_total} vs {mean_updated}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in samplers_tried.keys():\n",
    "    if \"q\" in s:\n",
    "        continue\n",
    "    plt.plot(\n",
    "        number_of_pivots_by_episode[s],\n",
    "        np.abs(estimated_values_by_episode[s]-true_value),\n",
    "        label=s)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Error in value estimate\")\n",
    "plt.ylim(-20, 800)\n",
    "plt.xlabel(\"Number of Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in samplers_tried.keys():\n",
    "    if \"q\" not in s:\n",
    "        continue\n",
    "    plt.plot(\n",
    "        number_of_pivots_by_episode[s],\n",
    "        np.abs(estimated_values_by_episode[s]-true_value),\n",
    "        label=s)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Error in value estimate\")\n",
    "plt.ylim(-20, 800)\n",
    "plt.xlabel(\"Number of Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_to_plot = [\"q1\", \"q0\", \"u10\", \"u500\"]\n",
    "# for s in samplers_tried.keys():\n",
    "for s in s_to_plot:\n",
    "    linestyle = \"-\" if \"q\" in s else \"--\"\n",
    "    plt.plot(\n",
    "        number_of_pivots_by_episode[s],\n",
    "        np.abs(estimated_values_by_episode[s]-true_value),\n",
    "        label=s, linestyle=linestyle)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Error in value estimate\")\n",
    "plt.ylim(-2, 50)\n",
    "plt.xlabel(\"Number of Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive_time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
