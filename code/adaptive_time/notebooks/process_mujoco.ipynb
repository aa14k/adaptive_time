{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from adaptive_time.utils import set_directory_in_project\n",
    "\n",
    "from importlib import reload\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_time import plot_utils\n",
    "from adaptive_time import utils\n",
    "from adaptive_time import run_lib\n",
    "from adaptive_time import value_est\n",
    "from adaptive_time.value_est import approx_integrators\n",
    "\n",
    "approx_integrators = reload(approx_integrators)\n",
    "run_lib = reload(run_lib)\n",
    "value_est = reload(value_est)\n",
    "plot_utils = reload(plot_utils)\n",
    "utils = reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_directory_in_project()\n",
    "data_dir = \"./data\"\n",
    "env_names = [env_name for env_name in os.listdir(data_dir) if not env_name.startswith(\".DS_Store\")]\n",
    "print(env_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers_tried = dict(\n",
    "    q100=approx_integrators.AdaptiveQuadratureIntegrator(tolerance=100),\n",
    "    q10=approx_integrators.AdaptiveQuadratureIntegrator(tolerance=10),\n",
    "    q1=approx_integrators.AdaptiveQuadratureIntegrator(tolerance=1),\n",
    "    q0=approx_integrators.AdaptiveQuadratureIntegrator(tolerance=0),\n",
    "    u1=approx_integrators.UniformlySpacedIntegrator(1),\n",
    "    u10=approx_integrators.UniformlySpacedIntegrator(50),\n",
    "    u100=approx_integrators.UniformlySpacedIntegrator(500),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_approx_integrals(\n",
    "    reward_file: str,\n",
    "    samplers_tried: dict,\n",
    "):\n",
    "    print(reward_file)\n",
    "    reward_sequences = np.load(reward_file)\n",
    "    idxes = np.where(reward_sequences[0, :][:, None] - reward_sequences[0, :][None, :] == 0)\n",
    "    \n",
    "    if len(idxes[0]) == len(idxes[1]):\n",
    "        assert np.sum(idxes[0] - idxes[1]) == 0\n",
    "    else:\n",
    "        assert 0\n",
    "\n",
    "    approx_integrals = {}\n",
    "    num_pivots = {}\n",
    "    for sampler_name, sampler in samplers_tried.items():\n",
    "        approx_integrals[sampler_name] = []\n",
    "        num_pivots[sampler_name] = []\n",
    "        for idx, reward_seq in enumerate(reward_sequences):\n",
    "            integral, all_pivots = sampler.integrate(reward_seq)\n",
    "            approx_integrals[sampler_name].append(integral)\n",
    "            num_pivots[sampler_name].append(len(all_pivots))\n",
    "        approx_integrals[sampler_name] = np.array(approx_integrals[sampler_name])\n",
    "        num_pivots[sampler_name] = np.array(num_pivots[sampler_name])\n",
    "\n",
    "    return {\n",
    "        \"reward_file\": reward_file,\n",
    "        \"approx_integrals\": approx_integrals,\n",
    "        \"num_pivots\": num_pivots,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env_name in tqdm(env_names):\n",
    "    if env_name in all_results:\n",
    "        continue\n",
    "    print(\"env: {}\".format(env_name))\n",
    "\n",
    "    env_dir = os.path.join(data_dir, env_name)\n",
    "    all_results.setdefault(env_name, {})\n",
    "    run_files = [run_file for run_file in os.listdir(env_dir) if not run_file.startswith(\".DS_Store\")]\n",
    "    all_results[env_name] = Parallel(\n",
    "        n_jobs=len(run_files)\n",
    "    )(\n",
    "        delayed(compute_approx_integrals)(\n",
    "            os.path.join(env_dir, run_file),\n",
    "            samplers_tried,\n",
    "        )\n",
    "        for run_file in run_files\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_results, open(\"./mujoco_val_est.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_budget = 100_000_000\n",
    "\n",
    "estimated_values_by_episode = {}\n",
    "number_of_pivots_by_episode = {}\n",
    "all_values_by_episode = {}\n",
    "weights = np.ones(len(reward_sequences)) / len(reward_sequences)\n",
    "\n",
    "true_value = np.sum(weights * np.sum(reward_sequences, axis=-1))\n",
    "\n",
    "for sampler_name, sampler in tqdm(samplers_tried.items()):\n",
    "    print(\"sampler_name:\", sampler_name)\n",
    "    # Update the value estimate with new samples until we run out of budget.\n",
    "    used_updates = 0\n",
    "    value_estimate = 0\n",
    "    num_samples = 0\n",
    "    all_values_by_episode[sampler_name] = []\n",
    "    # empirical_state_distr = np.zeros((num_trajs))\n",
    "\n",
    "    estimated_values_by_episode[sampler_name] = []\n",
    "    number_of_pivots_by_episode[sampler_name] = []\n",
    "\n",
    "    while used_updates < update_budget:\n",
    "        num_samples += 1\n",
    "        start_state = np.random.choice(len(reward_sequences), p=weights)\n",
    "        # empirical_state_distr[start_state] += 1\n",
    "        val_sample = approx_integrals[sampler_name][start_state]\n",
    "        all_values_by_episode[sampler_name].append(val_sample)\n",
    "        \n",
    "        value_estimate += (1.0/num_samples) * (val_sample - value_estimate)\n",
    "        used_updates += num_pivots[sampler_name][start_state]\n",
    "\n",
    "        estimated_values_by_episode[sampler_name].append(value_estimate)\n",
    "        number_of_pivots_by_episode[sampler_name].append(used_updates)\n",
    "    \n",
    "    # empirical_state_distr /= np.sum(empirical_state_distr)\n",
    "    # empirical_value = approx_integrals[sampler_name] @ empirical_state_distr\n",
    "\n",
    "\n",
    "# CODE TO SAMPLE MANY TRAJECOTRIES TO FIND AN EMPIRICAL DISTRIBUTION \n",
    "# episode_samples = 100_000\n",
    "# sampled_start_states = np.random.choice(num_trajs, size=(episode_samples,), p=weights)\n",
    "# # We now have samples, we determine the empirical state distribution.\n",
    "# empirical_state_distr = np.zeros((num_trajs))\n",
    "# values, counts = np.unique(sampled_start_states, return_counts=True)\n",
    "# empirical_state_distr[values] = counts\n",
    "# empirical_state_distr /= np.sum(empirical_state_distr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify final means.\n",
    "for key, value in estimated_values_by_episode.items():\n",
    "    mean_total = np.mean(all_values_by_episode[key])\n",
    "    mean_updated = value[-1]\n",
    "    print(\"sampler:\", key, \"mean_total:\", mean_total, \"mean_updated:\", mean_updated)\n",
    "    if abs(mean_total - mean_updated) > 0.01:\n",
    "        assert False, f\"Means don't match for {key}: {mean_total} vs {mean_updated}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in samplers_tried.keys():\n",
    "    if \"q\" in s:\n",
    "        continue\n",
    "    plt.plot(\n",
    "        number_of_pivots_by_episode[s],\n",
    "        np.abs(estimated_values_by_episode[s]-true_value),\n",
    "        label=s)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Error in value estimate\")\n",
    "plt.ylim(-20, 800)\n",
    "plt.xlabel(\"Number of Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in samplers_tried.keys():\n",
    "    if \"q\" not in s:\n",
    "        continue\n",
    "    plt.plot(\n",
    "        number_of_pivots_by_episode[s],\n",
    "        np.abs(estimated_values_by_episode[s]-true_value),\n",
    "        label=s)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Error in value estimate\")\n",
    "plt.ylim(-20, 800)\n",
    "plt.xlabel(\"Number of Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_to_plot = [\"q1\", \"q0\", \"u10\", \"u100\"]\n",
    "# for s in samplers_tried.keys():\n",
    "for s in s_to_plot:\n",
    "    linestyle = \"-\" if \"q\" in s else \"--\"\n",
    "    plt.plot(\n",
    "        number_of_pivots_by_episode[s],\n",
    "        np.abs(estimated_values_by_episode[s]-true_value),\n",
    "        label=s, linestyle=linestyle)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Error in value estimate\")\n",
    "plt.ylim(-2, 50)\n",
    "plt.xlabel(\"Number of Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive_time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
