{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Search\n",
    "\n",
    "It's become clear that our features are not good for this problem. This notebook will help us find better ones.\n",
    "\n",
    "Strategy:\n",
    "\n",
    "1. Generate the good trajectory of length ~616;\n",
    "2. Fit it with the OLS solution with different samplers (e.g. u5);\n",
    "    1. See how the pivots are fit\n",
    "    2. See how well we fit the rest of the examples\n",
    "\n",
    "We can try different regularization settings as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import gymnasium as gym\n",
    "\n",
    "import adaptive_time.utils\n",
    "import adaptive_time.features\n",
    "\n",
    "from adaptive_time import run_lib\n",
    "from adaptive_time import samplers\n",
    "from adaptive_time import environments\n",
    "from adaptive_time import mc2\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to /Users/szepi1991/Code/adaptive_time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/szepi1991/Code/adaptive_time'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptive_time.utils.set_directory_in_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_trajectory = True\n",
    "# regenerate_trajectory = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_to_evaluate = \"policy_to_eval_good.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracjectory length: 616\n",
      "total (undiscounted) return: 611.4690563799434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szepi1991/Code/adaptive_time/.venv/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment CartPole-OURS-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "if regenerate_trajectory:\n",
    "\n",
    "    run_lib.register_gym_envs()\n",
    "    env = gym.make('CartPole-OURS-v0')\n",
    "\n",
    "    # Just a specified sequence of actions.\n",
    "    policy_to_use = run_lib.ActionIterator(np.load(\n",
    "        adaptive_time.utils.get_abs_path(policy_to_evaluate)))\n",
    "\n",
    "    trajectory, early_term = environments.generate_trajectory(\n",
    "            env, policy=policy_to_use,\n",
    "            # env, policy=lambda s: policy(state=s, weights=weights),\n",
    "            termination_prob=0.0, max_steps=None)\n",
    "    \n",
    "    assert not early_term\n",
    "    print(\"Tracjectory length:\", len(trajectory))\n",
    "    print(\"total (undiscounted) return:\", sum(ts[2] for ts in trajectory))\n",
    "\n",
    "    print()\n",
    "    # Find stats about the states in the trajectory.\n",
    "    # Also find bounding boxes for the states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the features and regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(order):\n",
    "    phi = adaptive_time.features.Fourier_Features()\n",
    "    phi.init_fourier_features(4, order)\n",
    "    x_thres = 2.4\n",
    "    theta_thres = 0.418\n",
    "    phi.init_state_normalizers(\n",
    "        np.array([x_thres,2.0,theta_thres,1]),\n",
    "        np.array([-x_thres,-2.0,-theta_thres,-1]))\n",
    "    return phi\n",
    "\n",
    "phi = make_features(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 2],\n",
       "       ...,\n",
       "       [4, 4, 4, 2],\n",
       "       [4, 4, 4, 3],\n",
       "       [4, 4, 4, 4]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi.order_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20943951023931953"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "12 * 2 * math.pi / 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ols_monte_carlo(\n",
    "        trajectory, sampler: samplers.Sampler2,\n",
    "        phi, do_weighing, gamma, regularizer):\n",
    "    \"\"\"Processes a trajectory to find the weights using OLS Monte Carlo.\"\"\"\n",
    "\n",
    "    N = len(trajectory)\n",
    "    pivots = sampler.pivots(trajectory)\n",
    "    print(f\"Using {len(pivots)}/{N} samples.\")\n",
    "    print(f\"  regularizer={regularizer}.\")\n",
    "\n",
    "    feature_len = 2*phi.num_parameters\n",
    "\n",
    "    # Could optimize the below by iterating only over pivots,\n",
    "    # and using the discounted returns from `all_returns` directly.\n",
    "    all_returns = adaptive_time.utils.discounted_returns(trajectory, gamma)\n",
    "    all_features = np.zeros((N, feature_len))\n",
    "\n",
    "    pivot_idx = -1  # Start with the last one, count down.\n",
    "    prev_pivot = N-1\n",
    "    G = 0\n",
    "\n",
    "    # 2 is the number of actions.\n",
    "    x_sa = np.zeros((2, phi.num_parameters))\n",
    "    features_dt = np.zeros((feature_len, feature_len))\n",
    "    targets_dt = np.zeros(feature_len)\n",
    "    all_dts = []\n",
    "\n",
    "    for t in range(N-1,-1,-1):\n",
    "        state, action, reward, _ = trajectory[t]\n",
    "        G = gamma * G + reward\n",
    "\n",
    "        if G != all_returns[t]:\n",
    "            print(f\"Error in G: {G} != {all_returns[t]}\")\n",
    "            assert False\n",
    "        x = phi.get_fourier_feature(state)\n",
    "        x_sa = mc2.phi_sa(x, action, x_sa)\n",
    "        x_sa_flat = x_sa.flatten()\n",
    "        all_features[t] = x_sa_flat\n",
    "\n",
    "        if t in pivots:\n",
    "        # Process the pivot.\n",
    "            # all_pivot_features[pivot_idx] = x_sa_flat\n",
    "\n",
    "            if t == N-1:\n",
    "                dt = 1   # The weight for the last update.\n",
    "            else:\n",
    "                dt = prev_pivot - t\n",
    "                prev_pivot = t\n",
    "            if not do_weighing:\n",
    "                dt = 1\n",
    "            all_dts.append(dt)\n",
    "\n",
    "            # the scale is increasing over time, so we need to scale the features\n",
    "            features_dt = (\n",
    "                features_dt + dt * np.outer(x_sa_flat, x_sa_flat) / len(pivots))\n",
    "            targets_dt = targets_dt + dt * G * x_sa_flat / len(pivots)\n",
    "            # features_dt = features_dt + dt * np.outer(x_sa_flat, x_sa_flat)\n",
    "            # targets_dt = targets_dt + dt * G * x_sa_flat\n",
    "            pivot_idx -= 1\n",
    "\n",
    "    features_dt = features_dt + regularizer * np.eye(features_dt.shape[0])\n",
    "\n",
    "    features = features_dt.copy()\n",
    "    targets = targets_dt.copy()\n",
    "    # features = features + features_dt\n",
    "    # targets = targets + targets_dt/_TARGET_SCALAR\n",
    "\n",
    "    # print(\"dt's used: \", all_dts)\n",
    "\n",
    "    try:\n",
    "        # weights = np.linalg.solve(features, targets)\n",
    "        (weights, _, rank, _) = np.linalg.lstsq(\n",
    "            features,\n",
    "            targets\n",
    "        )\n",
    "        # print(np.min(x_sa_flat), np.max(x_sa_flat))\n",
    "        # # print(x_sa_flat.shape, features.shape, targets.shape)\n",
    "        # # print(weights.shape)\n",
    "        print(\"rank:\", rank)\n",
    "        # print(\"feat: {} targ: {}\".format(\n",
    "        #     np.linalg.norm(features/scale, ord=1), np.linalg.norm(targets/scale, ord=1)))\n",
    "        print(\"param: {}\".format(np.linalg.norm(weights)))\n",
    "        print(\"residual: {}\".format(np.linalg.norm(\n",
    "                features @ weights - targets), ord=1))\n",
    "\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Singular matrix in OLS. Using previous weights.\")\n",
    "\n",
    "    return (\n",
    "        weights,\n",
    "        (targets, features),\n",
    "        (np.array(all_returns), all_features, pivots)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_errors(returns, features, weights):\n",
    "    \"\"\"Check the fit of the predicted features to the returns.\"\"\"\n",
    "    return np.abs(features @ weights - returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn(trajectory, my_samplers, phi, gamma, regularizer):\n",
    "    all_weights = {}\n",
    "    all_pivots = {}\n",
    "    all_all_features = {}\n",
    "    all_all_returns = {}\n",
    "    for variant, sampler in my_samplers.items():\n",
    "        print()\n",
    "        print(\"-------- Sampler: \", variant)\n",
    "\n",
    "        weights, _, (returns, features, pivots) = ols_monte_carlo(\n",
    "            trajectory, sampler, phi, do_weighing=True, gamma=0.99999, regularizer=0.0)\n",
    "        \n",
    "        all_all_returns[variant] = returns\n",
    "        all_all_features[variant] = features\n",
    "        all_pivots[variant] = pivots\n",
    "        all_weights[variant] = weights\n",
    "\n",
    "        pivot_error = get_errors(returns[pivots], features[pivots], weights)\n",
    "        all_errors = get_errors(returns, features, weights)\n",
    "\n",
    "        print(\"Error in predictions (mean, max) -- pivots:\",\n",
    "            np.mean(pivot_error), np.max(pivot_error))\n",
    "        print(\"Error in predictions (mean, max) -- all:\",\n",
    "            np.mean(all_errors), np.max(all_errors))\n",
    "\n",
    "        print()\n",
    "        print(\"Extra details\")\n",
    "        print(\"Return in the start state:\", returns[0])\n",
    "    return all_weights, all_all_features, all_all_returns, all_pivots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- Sampler:  u1\n",
      "Using 616/616 samples.\n",
      "  regularizer=0.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xt/69nn93l959l31g_3b686nmsr0000gn/T/ipykernel_35489/2868353829.py:72: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  (weights, _, rank, _) = np.linalg.lstsq(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 248\n",
      "param: 4706236.460938105\n",
      "residual: 3.6232499789926523e-07\n",
      "Error in predictions (mean, max) -- pivots: 1.033666608274189 6.701330736801161\n",
      "Error in predictions (mean, max) -- all: 1.033666608274189 6.701330736801161\n",
      "\n",
      "Extra details\n",
      "Return in the start state: 609.5992462873995\n",
      "\n",
      "-------- Sampler:  u5\n",
      "Using 124/616 samples.\n",
      "  regularizer=0.0.\n",
      "rank: 119\n",
      "param: 3135288.592363637\n",
      "residual: 1.3272074367222689e-06\n",
      "Error in predictions (mean, max) -- pivots: 0.2589105680918419 2.7467300656601594\n",
      "Error in predictions (mean, max) -- all: 14348.046584071573 1394208.9709978688\n",
      "\n",
      "Extra details\n",
      "Return in the start state: 609.5992462873995\n",
      "\n",
      "-------- Sampler:  u20\n",
      "Using 31/616 samples.\n",
      "  regularizer=0.0.\n"
     ]
    }
   ],
   "source": [
    "my_samplers = dict(\n",
    "    u1=samplers.UniformSampler2(1),\n",
    "    u5=samplers.UniformSampler2(5),\n",
    "    u20=samplers.UniformSampler2(20),\n",
    ")\n",
    "\n",
    "phi = make_features(4)\n",
    "regularizer = 0.0\n",
    "\n",
    "all_weights, all_all_features, all_all_returns, all_pivots = learn(\n",
    "    trajectory, my_samplers, phi, gamma=0.99999, regularizer=regularizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "609.5992462873995"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_all_returns[\"u1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_plots(all_weights, all_all_features, all_all_returns, all_pivots, force_ylims):\n",
    "\n",
    "    for variant in all_weights.keys():\n",
    "\n",
    "        # num_rows = (num_episodes+1) // 2\n",
    "        # fig, ax = plt.subplots(num_rows, 2, figsize=(10, 3 * num_rows + 1),\n",
    "        #                        sharex=True, sharey=False)\n",
    "        # axes = ax.flatten()\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        \n",
    "        # Find predictions on all and the pivots.\n",
    "        feats = all_all_features[variant]\n",
    "        w = all_weights[variant]\n",
    "        ps = all_pivots[variant]\n",
    "        rets = all_all_returns[variant]\n",
    "\n",
    "        pred_rets_pivots = feats[ps] @ w\n",
    "        pred_rets_all = feats @ w\n",
    "\n",
    "        # action = 0\n",
    "        # pred_rets = pred_rets[np.where(acts_good == action)]\n",
    "        # true_rets = true_rets[np.where(acts_good == action)]\n",
    "\n",
    "        # First plot them everywhere.\n",
    "        axes[0].plot(pred_rets_all, label=\"Pred\", linestyle=\"\", marker=\".\")\n",
    "        axes[0].plot(rets, label=\"True\", linestyle=\"-\")\n",
    "        axes[0].set_title(f\"Predictions on all states\")\n",
    "        \n",
    "        # Plot only on the pivots.\n",
    "        axes[1].plot(ps, pred_rets_pivots, linestyle=\"\", marker=\".\")\n",
    "        axes[1].plot(ps, rets[ps], linestyle=\"-\")\n",
    "        axes[1].set_title(f\"Predictions on pivots\")\n",
    "\n",
    "        if force_ylims:\n",
    "            axes[0].set_ylim(-30, 630)\n",
    "            axes[1].set_ylim(-30, 630)\n",
    "\n",
    "        fig.legend()\n",
    "        fig.suptitle(f\"{variant}; Pred vs True Returns\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "make_plots(all_weights, all_all_features, all_all_returns, all_pivots,\n",
    "           force_ylims=False)\n",
    "        #    force_ylims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
