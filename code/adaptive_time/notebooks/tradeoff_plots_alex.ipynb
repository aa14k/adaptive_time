{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of Trade-offs\n",
    "\n",
    "In this notebook we compare different time discretization methods. First, we collect\n",
    "a trajectory data from the environment at a fine discretization level (this is also\n",
    "the discretization level we run the policy at -- right now, anyway). Then we compare:\n",
    "\n",
    "1. Using uniform discretization at different granularities, e.g. updating with every\n",
    "    1st, 10th, 100th, ...? interactions.\n",
    "2. Using the adaptive method with different tolarances.\n",
    "\n",
    "In order to average out randomness, we'll repeat each setting 3 times for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from adaptive_time.features import Fourier_Features\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import adaptive_time.utils\n",
    "from adaptive_time import environments\n",
    "from adaptive_time import mc2\n",
    "from adaptive_time import samplers\n",
    "\n",
    "seed = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register(\n",
    "    id=\"CartPole-OURS-v0\",\n",
    "    entry_point=\"adaptive_time.environments.cartpole:CartPoleEnv\",\n",
    "    vector_entry_point=\"adaptive_time.environments.cartpole:CartPoleVectorEnv\",\n",
    "    max_episode_steps=500,\n",
    "    reward_threshold=475.0,\n",
    ")\n",
    "\n",
    "def reset_randomness(seed, env):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # env.seed(seed)\n",
    "    env.action_space.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We run the same environment and simple policy twice,\n",
      "with different time discretizations. The policy we use\n",
      "will always go left, so the time discretization does not\n",
      "make a difference to the behaviour, and the total return\n",
      "will be the same.\n",
      "\n",
      "Total undiscounted return:  10.589912009424973\n",
      "Total undiscounted return:  100.17508472458734\n",
      "\n",
      "We can expect some difference because we may get an extra\n",
      "timesteps in the more fine-grained discretization, but the\n",
      "difference should be smallish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayoub/adaptive_time/env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.stepTime to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.stepTime` for environment variables or `env.get_wrapper_attr('stepTime')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample usage of the environment.\n",
    "print(\n",
    "    \"We run the same environment and simple policy twice,\\n\"\n",
    "    \"with different time discretizations. The policy we use\\n\"\n",
    "    \"will always go left, so the time discretization does not\\n\"\n",
    "    \"make a difference to the behaviour, and the total return\\n\"\n",
    "    \"will be the same.\")\n",
    "print()\n",
    "\n",
    "policy = lambda obs: 0\n",
    "\n",
    "env = gym.make('CartPole-OURS-v0')\n",
    "tau = 0.02\n",
    "env.stepTime(tau)\n",
    "\n",
    "reset_randomness(seed, env)\n",
    "traj = environments.generate_trajectory(env, seed, policy)\n",
    "total_return_1 = sum(ts[2] for ts in traj)\n",
    "print(\"Total undiscounted return: \", total_return_1)\n",
    "\n",
    "env = gym.make('CartPole-OURS-v0')\n",
    "tau = 0.002\n",
    "env.stepTime(tau)\n",
    "\n",
    "reset_randomness(seed, env)\n",
    "traj = environments.generate_trajectory(env, seed, policy)\n",
    "total_return_2 = sum(ts[2] for ts in traj)\n",
    "print(\"Total undiscounted return: \", total_return_2)\n",
    "\n",
    "#np.testing.assert_almost_equal(total_return_1, total_return_2, decimal=0)\n",
    "\n",
    "print()\n",
    "print(\n",
    "    \"We can expect some difference because we may get an extra\\n\"\n",
    "    \"timesteps in the more fine-grained discretization, but the\\n\"\n",
    "    \"difference should be smallish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** you must adjust the discount factor if changing time-scales!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = Fourier_Features()\n",
    "phi.init_fourier_features(4,3)\n",
    "x_thres = 4.8\n",
    "theta_thres = 0.418\n",
    "phi.init_state_normalizers(\n",
    "    np.array([x_thres,2.0,theta_thres,1]),\n",
    "    np.array([-x_thres,-2.0,-theta_thres,-1]))\n",
    "phi.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(\n",
    "        seed, env, sampler, epsilon, num_episodes, gamma, tqdm=None, print_trajectory=False):\n",
    "    \"\"\"Returns the number of episodes it took to solve the environment.\"\"\"\n",
    "    if tqdm is None:\n",
    "        tqdm_use = lambda x: x\n",
    "    total_pivots = 0\n",
    "    total_interactions = 0\n",
    "\n",
    "    # We record:\n",
    "    returns_per_episode_q = np.zeros((2, num_episodes))\n",
    "    average_returns_q = np.zeros((2, num_episodes))  # the cumulative average of the above\n",
    "    predicted_returns_q = np.zeros((2, num_episodes))\n",
    "\n",
    "    reset_randomness(seed, env)\n",
    "\n",
    "    observation, _ = env.reset(seed=seed)\n",
    "    d = len(phi.get_fourier_feature(observation))\n",
    "    assert d == phi.num_parameters\n",
    "    features = np.identity(2 * d)   # An estimate of A = xx^T\n",
    "    targets = np.zeros(2 * d)  # An estimate of b = xG\n",
    "    weights = np.zeros(2 * d)   # The weights that approximate A^{-1} b\n",
    "\n",
    "    x_0 = phi.get_fourier_feature([0,0,0,0])  # the initial state\n",
    "    x_sa0 = mc2.phi_sa(x_0, 0)\n",
    "    x_sa1 = mc2.phi_sa(x_0, 1)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        def policy(state):\n",
    "            if random.random() < epsilon:\n",
    "                return env.action_space.sample()\n",
    "            # Otherwise calculate the best action.\n",
    "            x = phi.get_fourier_feature(state)\n",
    "            qs = np.zeros(2)\n",
    "            for action in [0, 1]:\n",
    "                x_sa = mc2.phi_sa(x, action)\n",
    "                qs[action] = np.inner(x_sa.flatten(), weights)\n",
    "            # adaptive_time.utils.softmax(qs, 1)\n",
    "            return adaptive_time.utils.argmax(qs)\n",
    "\n",
    "        trajectory = environments.generate_trajectory(env, policy=policy, max_steps=100_000)\n",
    "        if trajectory is None:\n",
    "            #print(\"episode:\", episode)\n",
    "            #print(\"Did not drop it for a long time, returning!\")\n",
    "            return episode, total_pivots, total_interactions\n",
    "\n",
    "        total_interactions += len(trajectory)\n",
    "        print_trajectory = False\n",
    "        if print_trajectory:\n",
    "            print(\"trajectory-len: \", len(trajectory), \"; trajectory:\")\n",
    "            for idx, (o, a, r, o_) in enumerate(trajectory):\n",
    "                # * ignore reward, as it is always the same here.\n",
    "                # * o_ is the same as the next o.\n",
    "                print(f\"* {idx:4d}: o: {o}\\n\\t --> action: {a}\")\n",
    "\n",
    "        weights, targets, features, cur_avr_returns, num_pivots = mc2.ols_monte_carlo(\n",
    "            trajectory, sampler, tqdm_use, phi, weights, targets, features, x_0, gamma)\n",
    "        total_pivots += num_pivots\n",
    "        \n",
    "        # Store the empirical and predicted returns. For any episode, we may\n",
    "        # or may not have empirical returns for both actions. When we don't have an\n",
    "        # estimate, `nan` is returned.\n",
    "        returns_per_episode_q[:, episode] = cur_avr_returns\n",
    "        average_returns_q[:, episode] = np.nanmean(returns_per_episode_q[:, :episode+1], axis=1)\n",
    "\n",
    "        predicted_returns_q[0, episode] = np.inner(x_sa0.flatten(), weights)\n",
    "        predicted_returns_q[1, episode] = np.inner(x_sa1.flatten(), weights)\n",
    "        #print(\n",
    "        #    'episode:', episode,\n",
    "        #    ' empirical returns:' , returns_per_episode_q[:, episode],\n",
    "        #    ' predicted returns:' , predicted_returns_q[:, episode])\n",
    "    \n",
    "    return -1, total_pivots, total_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64558104ed8e45689ef20dabaa2035d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_20 <adaptive_time.samplers.AdaptiveQuadratureSampler2 object at 0x7fad1fa32f80>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0_10 <adaptive_time.samplers.AdaptiveQuadratureSampler2 object at 0x7fad1fa32260>\n",
      "q0_5 <adaptive_time.samplers.AdaptiveQuadratureSampler2 object at 0x7fad1fa32b90>\n",
      "q0_1 <adaptive_time.samplers.AdaptiveQuadratureSampler2 object at 0x7fad1fa31ed0>\n",
      "u5 <adaptive_time.samplers.UniformSampler2 object at 0x7fad1fa326b0>\n",
      "u10 <adaptive_time.samplers.UniformSampler2 object at 0x7fad1fa334f0>\n",
      "u20 <adaptive_time.samplers.UniformSampler2 object at 0x7fad1fa33b80>\n",
      "u40 <adaptive_time.samplers.UniformSampler2 object at 0x7fad1fa33460>\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 200\n",
    "epsilon = 0.0\n",
    "\n",
    "num_runs = 45\n",
    "\n",
    "tau = 0.002\n",
    "env.stepTime(tau)\n",
    "\n",
    "# tqdm_use = tqdm\n",
    "# tqdm_use = lambda x: x\n",
    "\n",
    "# sampler = samplers.AdaptiveQuadratureSampler2(tolerance=0.1)\n",
    "# sampler = samplers.AdaptiveQuadratureSampler2(tolerance=0.0)\n",
    "\n",
    "samplers_tried = dict(\n",
    "    q_20=samplers.AdaptiveQuadratureSampler2(tolerance=20),\n",
    "    q0_10=samplers.AdaptiveQuadratureSampler2(tolerance=10),\n",
    "    q0_5=samplers.AdaptiveQuadratureSampler2(tolerance=5),\n",
    "    q0_1=samplers.AdaptiveQuadratureSampler2(tolerance=1),\n",
    "    u5=samplers.UniformSampler2(5),\n",
    "    u10=samplers.UniformSampler2(10),\n",
    "    u20=samplers.UniformSampler2(20),\n",
    "    u40=samplers.UniformSampler2(40),\n",
    ")\n",
    "\n",
    "results = {}\n",
    "for name, sampler in tqdm(samplers_tried.items()):\n",
    "    print(name, sampler)\n",
    "    #results[name] = []\n",
    "    results[name] = Parallel(n_jobs = num_runs)(delayed(run_experiment)(seed+run, env, sampler, epsilon, num_episodes, gamma=0.99999, tqdm=None) for run in range(num_runs))\n",
    "\n",
    "'''\n",
    "for name, sampler in samplers_tried.items():\n",
    "    results[name] = []\n",
    "    for run in range(num_runs):\n",
    "        print()\n",
    "        print(f\"=============      Running experiment with sampler {name}, run={run}     =============\")\n",
    "        results[name].append(\n",
    "            run_experiment(seed+run, env, sampler, epsilon, num_episodes, gamma=0.999, tqdm=None))\n",
    "'''\n",
    "print()\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results, a list of num_episodes, and a list of num_pivots for the different seeds:\n",
      "* q_20\n",
      "    * num_episodes: ?? +- ??                full list: (1, 11, 7, 1, -1, -1, 3, 8, -1, -1, 1, 1, 13, 18, -1, 5, 1, -1, 6, 5, 8, 25, -1, -1, -1, -1, -1, 28, -1, -1, 3, 1, -1, 1, 7, -1, 1, 1, 2, 71, 8, 2, 6, -1, 18)\n",
      "    * num_pivots:   747.51 +- 160.21           full list: (12, 141, 68, 14, 1574, 4670, 24, 66, 1206, 1208, 10, 14, 124, 112, 3475, 277, 12, 1212, 54, 38, 56, 156, 3353, 1206, 2436, 1338, 1210, 320, 2796, 1208, 42, 16, 1208, 12, 48, 1204, 18, 12, 22, 434, 316, 20, 496, 1208, 192)\n",
      "    * num_interactions:   35459.67 +- 11367.15           full list: (239, 49923, 1655, 340, 37472, 477800, 473, 1759, 25273, 24791, 212, 320, 2838, 2894, 124683, 86738, 255, 24898, 1682, 865, 1293, 4252, 174641, 24895, 54624, 32834, 24817, 63005, 62869, 25207, 1087, 385, 24782, 260, 1444, 24711, 755, 323, 474, 8964, 71381, 506, 98334, 24779, 3953)\n",
      "* q0_10\n",
      "    * num_episodes: ?? +- ??                full list: (1, -1, -1, 1, -1, 14, 1, -1, 4, -1, 1, 1, 20, 3, 9, -1, 1, -1, -1, 2, 8, 9, -1, -1, 20, 4, -1, 28, 3, -1, 14, 1, -1, 1, 12, -1, 1, 1, 2, 115, -1, 2, -1, 13, 18)\n",
      "    * num_pivots:   1213.04 +- 262.94           full list: (14, 2281, 3544, 16, 4435, 152, 14, 8536, 44, 2006, 14, 16, 258, 73, 100, 2941, 14, 2135, 2383, 26, 90, 86, 3228, 2006, 397, 215, 2006, 434, 48, 2835, 158, 18, 2006, 16, 128, 2004, 22, 16, 30, 1156, 3076, 26, 5199, 134, 251)\n",
      "    * num_interactions:   32306.20 +- 8225.32           full list: (239, 84265, 52523, 340, 86495, 2130, 227, 205070, 634, 24791, 212, 320, 4118, 1700, 1416, 127321, 255, 51252, 33448, 417, 1293, 1664, 145670, 24892, 6986, 7617, 24817, 61805, 1007, 66956, 2269, 385, 24782, 260, 2336, 24711, 755, 323, 477, 14376, 115490, 506, 241466, 1810, 3953)\n",
      "* q0_5\n",
      "    * num_episodes: ?? +- ??                full list: (1, -1, 8, -1, 6, -1, 1, -1, 4, -1, 1, 1, 1, 9, 5, 89, 1, -1, 11, 2, 7, 15, -1, -1, 1, 2, -1, 92, 49, 49, 7, 18, -1, 1, -1, -1, 1, 1, 2, 26, 8, 4, 17, 10, 18)\n",
      "    * num_pivots:   1883.64 +- 1004.72           full list: (16, 2888, 129, 2407, 91, 2791, 16, 2941, 54, 2405, 16, 17, 22, 141, 70, 1846, 16, 2408, 229, 29, 92, 237, 2778, 2404, 20, 73, 2407, 1344, 786, 898, 136, 633, 2405, 17, 2407, 2404, 25, 16, 33, 319, 293, 55, 46016, 129, 305)\n",
      "    * num_interactions:   18954.73 +- 4329.31           full list: (239, 82142, 1631, 24817, 1561, 30545, 227, 33239, 634, 24791, 212, 320, 423, 1732, 942, 85838, 255, 24959, 4052, 417, 1171, 2731, 116160, 24894, 401, 2352, 24817, 70363, 14858, 14594, 2491, 8843, 24782, 260, 25028, 24711, 755, 323, 477, 3480, 66104, 752, 98097, 1428, 4115)\n",
      "* q0_1\n",
      "    * num_episodes: ?? +- ??                full list: (18, -1, 52, 3, -1, 29, -1, 2, 2, 1, 1, 1, -1, 3, -1, -1, -1, 11, 4, 1, 2, 7, 39, -1, 1, -1, 1, -1, -1, 2, 2, 7, 1, 17, 5, 1, 1, -1, 2, -1, -1, 1, -1, -1, 17)\n",
      "    * num_pivots:   2126.49 +- 426.09           full list: (3927, 4808, 1104, 70, 3613, 564, 3608, 55, 44, 29, 24, 31, 5007, 71, 3934, 3964, 3610, 1167, 102, 29, 111, 176, 5783, 3606, 32, 5694, 27, 3707, 5795, 63, 51, 461, 27, 330, 109, 28, 61, 6371, 567, 3808, 14871, 31, 4242, 3611, 369)\n",
      "    * num_interactions:   20301.36 +- 4298.53           full list: (29956, 78131, 8752, 598, 24832, 4103, 24704, 621, 372, 314, 212, 320, 41171, 552, 27913, 30676, 24732, 27092, 1142, 294, 1100, 1655, 115352, 24694, 401, 53284, 340, 77259, 52574, 645, 427, 3714, 305, 2279, 948, 234, 755, 47817, 4108, 27120, 112878, 383, 30989, 24779, 3034)\n",
      "* u5\n",
      "    * num_episodes: ?? +- ??                full list: (2, -1, 1, 1, 2, -1, 2, -1, -1, 1, 1, 9, 3, -1, 7, -1, 29, -1, 3, 2, 8, 1, -1, 1, 2, 2, -1, -1, 1, -1, 1, 5, -1, -1, 2, 1, 1, -1, 1, 1, 25, -1, 154, 2, 2)\n",
      "    * num_pivots:   10747.13 +- 2416.77           full list: (100, 14798, 60, 68, 96, 28041, 83, 28531, 9143, 63, 43, 395, 2056, 14722, 354, 52239, 15220, 16180, 677, 84, 2252, 62, 17820, 44, 699, 131, 38538, 20880, 71, 38209, 61, 411, 22761, 30929, 96, 47, 151, 74543, 55, 71, 15410, 16105, 21107, 86, 129)\n",
      "    * num_interactions:   53595.44 +- 12061.70           full list: (497, 73589, 296, 340, 477, 139802, 409, 142285, 45385, 314, 212, 1961, 10276, 73257, 1757, 260748, 76038, 80638, 3379, 417, 11245, 306, 88692, 217, 3489, 653, 192309, 103801, 351, 190633, 304, 2053, 113617, 154263, 475, 234, 755, 372295, 272, 354, 76987, 80147, 105201, 425, 640)\n",
      "* u10\n",
      "    * num_episodes: ?? +- ??                full list: (2, 3, -1, -1, -1, 2, 1, 1, -1, 1, 1, 4, -1, 7, 11, 2, 9, -1, 2, -1, 8, 1, -1, 1, -1, 4, -1, -1, 5, 1, 9, 136, -1, -1, 2, 1, -1, 1, 1, 14, 3, -1, -1, 2, 3)\n",
      "    * num_pivots:   4364.42 +- 902.41           full list: (80, 4937, 22840, 13591, 7699, 47, 23, 43, 21009, 32, 22, 104, 9589, 528, 396, 8472, 494, 20272, 45, 4421, 1285, 31, 2775, 22, 3055, 164, 6605, 10119, 124, 53, 1463, 5722, 12059, 5183, 56, 24, 6156, 33, 28, 790, 6611, 5161, 14110, 44, 82)\n",
      "    * num_interactions:   43282.11 +- 8979.25           full list: (799, 49358, 227456, 135027, 76071, 461, 227, 430, 209286, 314, 212, 1023, 94909, 5237, 3905, 84709, 4917, 201830, 444, 43262, 12807, 306, 26384, 217, 29208, 1623, 65486, 100240, 1208, 522, 14581, 56614, 119630, 50652, 551, 234, 60485, 323, 272, 7824, 66104, 51068, 140252, 425, 802)\n",
      "* u20\n",
      "    * num_episodes: ?? +- ??                full list: (1, -1, 1, 10, -1, 2, 1, -1, 11, 1, 5, 1, 14, 1, -1, -1, 5, 15, -1, -1, -1, -1, -1, 1, 3, 4, -1, -1, -1, 5, 3, 2, 14, 1, 5, 1, 2, 5, 1, 54, -1, 1, -1, 2, 60)\n",
      "    * num_pivots:   2242.76 +- 497.94           full list: (12, 3923, 15, 125, 3192, 24, 12, 2545, 187, 16, 169, 16, 434, 16, 1591, 10129, 144, 2004, 5654, 1567, 3271, 6226, 7918, 11, 52, 64, 6603, 5148, 9391, 76, 47, 27, 238, 13, 292, 12, 65, 65, 14, 3332, 5460, 20, 13931, 23, 6850)\n",
      "    * num_interactions:   44086.51 +- 9854.13           full list: (239, 75185, 296, 2431, 60992, 461, 227, 48948, 3607, 314, 3331, 320, 8485, 302, 28954, 200724, 2833, 39961, 111064, 29619, 63993, 122313, 156842, 217, 995, 1237, 129288, 100150, 186226, 1455, 899, 508, 4638, 260, 5798, 234, 1294, 1221, 272, 66227, 107623, 383, 276696, 426, 136405)\n",
      "* u40\n",
      "    * num_episodes: ?? +- ??                full list: (-1, 5, 1, 1, -1, 7, -1, -1, 2, -1, 1, 4, 1, 11, -1, 17, 5, 6, 1, 4, -1, 2, -1, 1, 1, -1, 1, -1, -1, 2, 96, 85, 2, 2, -1, 3, 1, -1, -1, 2, 4, 1, 16, 12, 1)\n",
      "    * num_pivots:   961.38 +- 210.28           full list: (805, 1253, 8, 9, 1590, 102, 802, 2415, 11, 3545, 6, 26, 11, 152, 888, 2126, 39, 670, 8, 62, 1996, 12, 1620, 6, 11, 1342, 9, 859, 6090, 18, 4736, 4306, 13, 12, 1366, 19, 19, 813, 803, 13, 1654, 10, 2902, 92, 13)\n",
      "    * num_interactions:   36733.42 +- 8265.58           full list: (24875, 49993, 296, 340, 59722, 3960, 24704, 92699, 372, 136184, 212, 948, 423, 5799, 28417, 84709, 1475, 26705, 286, 2346, 74765, 462, 57846, 217, 401, 46443, 340, 31658, 239378, 645, 187686, 170410, 477, 430, 53336, 683, 755, 29305, 26516, 477, 66104, 383, 115868, 3437, 517)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print()\n",
    "print(\"Results, a list of num_episodes, and a list of num_pivots for the different seeds:\")\n",
    "for name, sub_results in results.items():\n",
    "    num_episodes, num_pivots, num_interactions = zip(*sub_results)\n",
    "    print(f\"* {name}\")\n",
    "    if -1 in num_episodes:\n",
    "        num_eps_stats = f\"?? +- ??\"\n",
    "    else:\n",
    "        mean_num_episodes = np.mean(num_episodes)\n",
    "        std_err_episodes = np.std(num_episodes) / np.sqrt(len(num_episodes))\n",
    "        num_eps_stats = f\"{np.mean(num_episodes):.2f} +- {std_err_episodes:.2f}\"\n",
    "\n",
    "    std_err_pivots = np.std(num_pivots) / np.sqrt(len(num_pivots))\n",
    "    std_err_num_interactions = np.std(num_interactions) / np.sqrt(len(num_interactions))\n",
    "    print(f\"    * num_episodes: {num_eps_stats}                full list: {num_episodes}\")\n",
    "    print(f\"    * num_pivots:   {np.mean(num_pivots):.2f} +- {std_err_pivots:.2f}           full list: {num_pivots}\")\n",
    "    print(f\"    * num_interactions:   {np.mean(num_interactions):.2f} +- {std_err_num_interactions:.2f}\"\n",
    "          f\"           full list: {num_interactions}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
