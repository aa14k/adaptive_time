{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from adaptive_time.features import Fourier_Features\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import adaptive_time.utils\n",
    "\n",
    "seed = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register(\n",
    "    id=\"CartPole-OURS-v0\",\n",
    "    entry_point=\"adaptive_time.environments.cartpole:CartPoleEnv\",\n",
    "    vector_entry_point=\"adaptive_time.environments.cartpole:CartPoleVectorEnv\",\n",
    "    max_episode_steps=500,\n",
    "    reward_threshold=475.0,\n",
    ")\n",
    "\n",
    "def reset_randomness(seed, env):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # env.seed(seed)\n",
    "    env.action_space.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-OURS-v0')\n",
    "tau = 0.02\n",
    "env.stepTime(tau)\n",
    "\n",
    "def generate_trajectory(env, policy=None):\n",
    "    observation, _ = env.reset()\n",
    "    trajectory = []\n",
    "    terminated = False\n",
    "    steps = 0\n",
    "    if policy is None:\n",
    "        policy = lambda x: env.action_space.sample()\n",
    "    while not terminated:\n",
    "        steps += 1\n",
    "        action = policy(observation)\n",
    "        observation_, reward, terminated, truncated, info = env.step(action)\n",
    "        trajectory.append([observation, action, reward, observation_])\n",
    "        observation = observation_\n",
    "\n",
    "        if steps % 5000 == 0:\n",
    "            print('Good trajectory!', steps)\n",
    "\n",
    "\n",
    "    return trajectory\n",
    "\n",
    "reset_randomness(seed, env)\n",
    "trajectory = generate_trajectory(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(xs, tol, idxes):\n",
    "    N = len(xs[0])\n",
    "    if N > 2:\n",
    "        Q = N * (xs[0,0] + xs[0,-1]) / 2\n",
    "        idxes[int(xs[1,0])] = 1\n",
    "        idxes[int(xs[1,-1])] = 1\n",
    "    else:\n",
    "        idxes[int(xs[1,0])] = 1\n",
    "        idxes[int(xs[1,-1])] = 1\n",
    "        return sum(xs[0])\n",
    "    truth = sum(xs[0])\n",
    "    if np.abs(Q - truth) > tol:\n",
    "        c = int(np.floor(N / 2))\n",
    "        Q = integrate(xs[:,:c], tol / 2, idxes) + integrate(xs[:,c:], tol / 2, idxes)\n",
    "    return Q\n",
    "    \n",
    "\n",
    "\n",
    "def get_return(pivots, rewards):\n",
    "    sums = 0\n",
    "    for i in range(0,len(pivots)-1):\n",
    "        idx1 = pivots[i]\n",
    "        idx2 = pivots[i+1]\n",
    "        sums += len(rewards[idx1:idx2+1]) * (rewards[idx1])\n",
    "    return sums\n",
    "    \n",
    "\n",
    "\n",
    "def phi_sa(phi_x, a, prev_phi_sa=None):\n",
    "    \"\"\"Form the (state, action) feature, potentially reusing memory.\n",
    "    \n",
    "    - phi_x: the state feature\n",
    "    - a: the action\n",
    "    - prev_phi_sa: the previous state,action feature, which can be\n",
    "      reused to avoid memory allocation.\n",
    "\n",
    "    Returns the feature as a (2, d) array. Use a flat copy.\n",
    "    \"\"\"\n",
    "    if prev_phi_sa is not None:\n",
    "        prev_phi_sa.fill(0)\n",
    "        phi_sa = prev_phi_sa\n",
    "    else:\n",
    "        phi_sa = np.zeros((2, phi_x.size))\n",
    "    phi_sa[a] = phi_x\n",
    "    return phi_sa\n",
    "\n",
    "\n",
    "def ols_monte_carlo_quad(\n",
    "        env, phi, weights, targets, features, x0, policy=None, print_trajectory=False, gamma = 0.999):\n",
    "    trajectory = generate_trajectory(env, policy=policy)\n",
    "    if print_trajectory:\n",
    "        print(\"trajectory-len: \", len(trajectory), \"; trajectory:\")\n",
    "        for idx, (o, a, r, o_) in enumerate(trajectory):\n",
    "            # * ignore reward, as it is always the same here.\n",
    "            # * o_ is the same as the next o.\n",
    "            print(f\"* {idx:4d}: o: {o}\\n\\t --> action: {a}\")\n",
    "    N = len(trajectory)\n",
    "    rewards = np.zeros((2,N))\n",
    "    for idx, traj in enumerate(trajectory):\n",
    "        rewards[0, idx] = traj[2]\n",
    "        rewards[1, idx] = idx\n",
    "    idxes = {}\n",
    "    _ = integrate(rewards, 0.1, idxes)\n",
    "    pivots = list(idxes.keys())\n",
    "    print(len(idxes), N)\n",
    "    G = 0\n",
    "    x_sa = np.zeros((2, phi.num_parameters))\n",
    "    returns_a0 = []  # from x0 (the initial state), action 0\n",
    "    returns_a1 = []  # from x0 (the initial state), action 1\n",
    "    for t in tqdm(range(N-1,-1,-1)):\n",
    "        if t in pivots:\n",
    "            state, action, reward, _ = trajectory[t]\n",
    "            G = gamma * G + reward\n",
    "            x = phi.get_fourier_feature(state)\n",
    "            # Record empirical returns.\n",
    "            if np.linalg.norm(x-x0) < 0.00001:\n",
    "                if action == 0:\n",
    "                    returns_a0.append(G)\n",
    "                    returns_a1.append(-0)\n",
    "                elif action == 1:\n",
    "                    returns_a1.append(G)\n",
    "                    returns_a0.append(-0)\n",
    "\n",
    "            x_sa = phi_sa(x, action, x_sa)\n",
    "            x_sa_flat = x_sa.flatten()\n",
    "\n",
    "            features += np.outer(x_sa_flat, x_sa_flat)\n",
    "            targets += G * x_sa_flat\n",
    "        try:\n",
    "            weights = np.linalg.solve(features, targets)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Singular matrix in OLS. Using previous weights.\")\n",
    "    else:\n",
    "        G = gamma * G + reward\n",
    "    return weights, targets, features, (np.mean(returns_a0), np.mean(returns_a1))\n",
    "\n",
    "\n",
    "def ols_monte_carlo_q(\n",
    "        env, phi, weights, targets, features, x0, policy=None, print_trajectory=False, gamma = 0.999):\n",
    "    trajectory = generate_trajectory(env, policy=policy)\n",
    "    if print_trajectory:\n",
    "        print(\"trajectory-len: \", len(trajectory), \"; trajectory:\")\n",
    "        for idx, (o, a, r, o_) in enumerate(trajectory):\n",
    "            # * ignore reward, as it is always the same here.\n",
    "            # * o_ is the same as the next o.\n",
    "            print(f\"* {idx:4d}: o: {o}\\n\\t --> action: {a}\")\n",
    "    N = len(trajectory)\n",
    "    G = 0\n",
    "    x_sa = np.zeros((2, phi.num_parameters))\n",
    "    returns_a0 = []  # from x0 (the initial state), action 0\n",
    "    returns_a1 = []  # from x0 (the initial state), action 1\n",
    "    for t in tqdm(range(N-1,-1,-1)):\n",
    "        state, action, reward, _ = trajectory[t]\n",
    "        G = gamma*G + reward\n",
    "        x = phi.get_fourier_feature(state)\n",
    "        # Record empirical returns.\n",
    "        if np.linalg.norm(x-x0) < 0.00001:\n",
    "            if action == 0:\n",
    "                returns_a0.append(G)\n",
    "                returns_a1.append(-0)\n",
    "            elif action == 1:\n",
    "                returns_a1.append(G)\n",
    "                returns_a0.append(-0)\n",
    "\n",
    "        x_sa = phi_sa(x, action, x_sa)\n",
    "        x_sa_flat = x_sa.flatten()\n",
    "\n",
    "        features += np.outer(x_sa_flat, x_sa_flat)\n",
    "        targets += G * x_sa_flat\n",
    "    try:\n",
    "        weights = np.linalg.solve(features, targets)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Singular matrix in OLS. Using previous weights.\")\n",
    "    return weights, targets, features, (np.mean(returns_a0), np.mean(returns_a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "[array([0., 0., 0., 0.], dtype=float32), 1, 1.0, array([ 0.        ,  0.19512194,  0.        , -0.29268292], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(len(trajectory))\n",
    "print(trajectory[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = Fourier_Features()\n",
    "phi.init_fourier_features(4,4)\n",
    "x_thres = 4.8\n",
    "theta_thres = 0.418\n",
    "phi.init_state_normalizers(np.array([x_thres,2.0,theta_thres,1]), np.array([-x_thres,-2.0,-theta_thres,-1]))\n",
    "phi.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1fabc4f2764ec686befd69a9f7c9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0  empirical returns: [70.91348277  0.        ]  predicted returns: [70.26398947 59.70663005]\n",
      "40 123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71d68bc45d84ef98120db43969aee71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1  empirical returns: [27.32949402  0.        ]  predicted returns: [52.61432151 59.70663005]\n",
      "37 144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5be95a0b3e04d90ba5146d1ac813ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2  empirical returns: [ 0.         22.88289545]  predicted returns: [52.65025234 25.65344876]\n",
      "93 345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2159672031674a5187c4dade9fb6fa93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3  empirical returns: [71.62932932  0.        ]  predicted returns: [58.96130128 28.32850007]\n",
      "363 1048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede43cfa223d4ed6a4ca0a5d5baab755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4  empirical returns: [235.76468763   0.        ]  predicted returns: [103.90599528  43.26457479]\n",
      "52 178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a54d1d43a1439b8c5128a0da1bae39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5  empirical returns: [37.39840699  0.        ]  predicted returns: [87.45499411 19.87490025]\n",
      "48 189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be617e098c4f43e28ad3420f685e5085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6  empirical returns: [33.94225455  0.        ]  predicted returns: [76.96004832  7.52358356]\n",
      "121 428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1ab0e2f66749c8a4e9969efc266752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7  empirical returns: [97.02129755  0.        ]  predicted returns: [ 84.0366012  -27.11737255]\n",
      "281 1030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b264e8f3881438cb2fe474d66d1f11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1030 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 8  empirical returns: [208.71095121   0.        ]  predicted returns: [100.31733236  17.60979711]\n",
      "55 257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8abb035f25a4d329dffe741e213ff2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 9  empirical returns: [38.87036898  0.        ]  predicted returns: [94.6025822  14.46917879]\n",
      "281 956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5bd128353d4d8b8fa5da75c4e514fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10  empirical returns: [205.04284347   0.        ]  predicted returns: [113.26439191  93.39009755]\n",
      "129 1026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c435dcc2b0f4d97bf84988f71be768d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 500\n",
    "epsilon = 0.1\n",
    "\n",
    "tau = 0.002\n",
    "env.stepTime(tau)\n",
    "\n",
    "# We record:\n",
    "returns_per_episode_q = np.zeros((2, num_episodes))\n",
    "average_returns_q = np.zeros((2, num_episodes))  # the cumulative average of the above\n",
    "predicted_returns_q = np.zeros((2, num_episodes))\n",
    "\n",
    "reset_randomness(seed, env)\n",
    "\n",
    "observation, _ = env.reset()\n",
    "d = len(phi.get_fourier_feature(observation))\n",
    "assert d == phi.num_parameters\n",
    "features = np.identity(2 * d)   # An estimate of A = xx^T\n",
    "targets = np.zeros(2 * d)  # An estimate of b = xG\n",
    "weights = np.zeros(2 * d)   # The weights that approximate A^{-1} b\n",
    "\n",
    "x_0 = phi.get_fourier_feature([0,0,0,0])  # the initial state\n",
    "x_sa0 = phi_sa(x_0, 0)\n",
    "x_sa1 = phi_sa(x_0, 1)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    def policy(state):\n",
    "        if random.random() < epsilon:\n",
    "            return env.action_space.sample()\n",
    "        # Otherwise calculate the best action.\n",
    "        x = phi.get_fourier_feature(state)\n",
    "        qs = np.zeros(2)\n",
    "        for action in [0, 1]:\n",
    "            x_sa = phi_sa(x, action)\n",
    "            qs[action] = np.inner(x_sa.flatten(), weights)\n",
    "        # adaptive_time.utils.softmax(qs, 1)\n",
    "        return adaptive_time.utils.argmax(qs)\n",
    "\n",
    "    weights, targets, features, cur_avr_returns = ols_monte_carlo_quad(\n",
    "        env, phi, weights, targets, features, x_0, policy=policy, print_trajectory=False)\n",
    "    \n",
    "    # Store the empirical and predicted returns. For any episode, we may\n",
    "    # or may not have empirical returns for both actions. When we don't have an\n",
    "    # estimate, `nan` is returned.\n",
    "    returns_per_episode_q[:, episode] = cur_avr_returns\n",
    "    average_returns_q[:, episode] = np.nanmean(returns_per_episode_q[:, :episode+1], axis=1)\n",
    "\n",
    "    predicted_returns_q[0, episode] = np.inner(x_sa0.flatten(), weights)\n",
    "    predicted_returns_q[1, episode] = np.inner(x_sa1.flatten(), weights)\n",
    "    print(\n",
    "        'episode:', episode,\n",
    "        ' empirical returns:' , returns_per_episode_q[:, episode],\n",
    "        ' predicted returns:' , predicted_returns_q[:, episode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo2(xs,tol,level):\n",
    "    c=int(np.floor(len(xs)/2))\n",
    "    #print(xs, c)\n",
    "    f = lambda xs: len(xs)*(xs[0]+xs[-1])/2 if len(xs) else 0\n",
    "    if abs(f(xs) - (r:=f(xs[:c]) + f(xs[c:]))) < tol: return 1, r, [level+c]\n",
    "    else: \n",
    "        x, a, cs_a = foo2(xs[:c],tol/2, level)\n",
    "        y, b, cs_b = foo2(xs[c:],tol/2, level+c)\n",
    "        return x+y+1, a+b, cs_a + cs_b + [level+c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good trajectory! 5000\n"
     ]
    }
   ],
   "source": [
    "tau = 0.0002\n",
    "env.stepTime(tau)\n",
    "reset_randomness(seed, env)\n",
    "trajectory = generate_trajectory(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for traj in trajectory:\n",
    "    rewards.append(traj[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xs = [1,2]\n",
    "rewards = [1,2,3,4,5,6,7]\n",
    "x,y,z= foo2(rewards,0.01,0)\n",
    "z.append(0)\n",
    "z.sort()\n",
    "if len(rewards)-1 not in z:\n",
    "    z.append(len(rewards)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = 0\n",
    "for i in range(0,len(z)-1):\n",
    "    idx1 = z[i]\n",
    "    idx2 = z[i+1]\n",
    "    sums += len(rewards[idx1:idx2+1]) * (rewards[idx1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y - sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 6]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "60\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "pivot = [0, 50, 60, 80]\n",
    "\n",
    "for i in range(100):\n",
    "    if i in pivot:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good trajectory! 5000\n",
      "Good trajectory! 10000\n",
      "Good trajectory! 15000\n",
      "Good trajectory! 20000\n",
      "Good trajectory! 25000\n"
     ]
    }
   ],
   "source": [
    "trajectory = generate_trajectory(env, policy=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for traj in trajectory:\n",
    "    rewards.append(traj[2])\n",
    "\n",
    "\n",
    "def foo2(xs,tol,level):\n",
    "    c=int(np.floor(len(xs)/2))\n",
    "    #print(xs, c)\n",
    "    f = lambda xs: len(xs)*(xs[0]+xs[-1])/2 if len(xs) else 0\n",
    "    if abs(f(xs) - (r:=f(xs[:c]) + f(xs[c:]))) < tol: return 0, r, []\n",
    "    else: \n",
    "        x, a, cs_a = foo2(xs[:c],tol/2, level)\n",
    "        y, b, cs_b = foo2(xs[c:],tol/2, level+c)\n",
    "        return x+y+1, a+b, cs_a + cs_b + [level+c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = foo2(rewards, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5147"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.76025212035529"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y-sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(z.count(x) > 1 for x in z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0 not in z:\n",
    "    z.append(0)\n",
    "if len(rewards)-1 not in z:\n",
    "    z.append(len(rewards)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 18,\n",
       " 19,\n",
       " 21,\n",
       " 22,\n",
       " 24,\n",
       " 25,\n",
       " 27,\n",
       " 28,\n",
       " 30,\n",
       " 31,\n",
       " 33,\n",
       " 34,\n",
       " 36,\n",
       " 37,\n",
       " 39,\n",
       " 40,\n",
       " 42,\n",
       " 43,\n",
       " 45,\n",
       " 47,\n",
       " 49,\n",
       " 50,\n",
       " 52,\n",
       " 53,\n",
       " 55,\n",
       " 56,\n",
       " 58,\n",
       " 59,\n",
       " 61,\n",
       " 62,\n",
       " 64,\n",
       " 65,\n",
       " 67,\n",
       " 68,\n",
       " 70,\n",
       " 71,\n",
       " 73,\n",
       " 74,\n",
       " 76,\n",
       " 77,\n",
       " 79,\n",
       " 80,\n",
       " 82,\n",
       " 83,\n",
       " 85,\n",
       " 86,\n",
       " 88,\n",
       " 89,\n",
       " 91,\n",
       " 92,\n",
       " 94,\n",
       " 96,\n",
       " 98,\n",
       " 99,\n",
       " 101,\n",
       " 102,\n",
       " 104,\n",
       " 105,\n",
       " 107,\n",
       " 108,\n",
       " 110,\n",
       " 111,\n",
       " 113,\n",
       " 114,\n",
       " 116,\n",
       " 117,\n",
       " 119,\n",
       " 120,\n",
       " 122,\n",
       " 123,\n",
       " 125,\n",
       " 126,\n",
       " 128,\n",
       " 129,\n",
       " 131,\n",
       " 132,\n",
       " 134,\n",
       " 135,\n",
       " 137,\n",
       " 138,\n",
       " 140,\n",
       " 141,\n",
       " 143,\n",
       " 145,\n",
       " 147,\n",
       " 148,\n",
       " 150,\n",
       " 151,\n",
       " 153,\n",
       " 154,\n",
       " 156,\n",
       " 157,\n",
       " 159,\n",
       " 160,\n",
       " 162,\n",
       " 163,\n",
       " 165,\n",
       " 166,\n",
       " 168,\n",
       " 169,\n",
       " 171,\n",
       " 172,\n",
       " 174,\n",
       " 175,\n",
       " 177,\n",
       " 178,\n",
       " 180,\n",
       " 181,\n",
       " 183,\n",
       " 184,\n",
       " 186,\n",
       " 187,\n",
       " 189,\n",
       " 190,\n",
       " 192,\n",
       " 194,\n",
       " 196,\n",
       " 197,\n",
       " 199,\n",
       " 200,\n",
       " 202,\n",
       " 203,\n",
       " 205,\n",
       " 206,\n",
       " 208,\n",
       " 209,\n",
       " 211,\n",
       " 212,\n",
       " 214,\n",
       " 215,\n",
       " 217,\n",
       " 218,\n",
       " 220,\n",
       " 221,\n",
       " 223,\n",
       " 224,\n",
       " 226,\n",
       " 229,\n",
       " 230,\n",
       " 232,\n",
       " 233,\n",
       " 235,\n",
       " 236,\n",
       " 238,\n",
       " 239,\n",
       " 241,\n",
       " 243,\n",
       " 245,\n",
       " 246,\n",
       " 248,\n",
       " 249,\n",
       " 251,\n",
       " 252,\n",
       " 254,\n",
       " 255,\n",
       " 257,\n",
       " 258,\n",
       " 260,\n",
       " 261,\n",
       " 263,\n",
       " 264,\n",
       " 266,\n",
       " 267,\n",
       " 269,\n",
       " 270,\n",
       " 272,\n",
       " 273,\n",
       " 275,\n",
       " 276,\n",
       " 278,\n",
       " 279,\n",
       " 281,\n",
       " 287,\n",
       " 288,\n",
       " 290,\n",
       " 294,\n",
       " 295,\n",
       " 297,\n",
       " 298,\n",
       " 300,\n",
       " 301,\n",
       " 303,\n",
       " 304,\n",
       " 306,\n",
       " 307,\n",
       " 309,\n",
       " 310,\n",
       " 312,\n",
       " 313,\n",
       " 315,\n",
       " 316,\n",
       " 318,\n",
       " 319,\n",
       " 321,\n",
       " 322,\n",
       " 324,\n",
       " 325,\n",
       " 327,\n",
       " 328,\n",
       " 330,\n",
       " 331,\n",
       " 333,\n",
       " 334,\n",
       " 336,\n",
       " 337,\n",
       " 339,\n",
       " 341,\n",
       " 343,\n",
       " 344,\n",
       " 346,\n",
       " 347,\n",
       " 349,\n",
       " 350,\n",
       " 352,\n",
       " 355,\n",
       " 356,\n",
       " 358,\n",
       " 359,\n",
       " 361,\n",
       " 362,\n",
       " 364,\n",
       " 366,\n",
       " 368,\n",
       " 369,\n",
       " 371,\n",
       " 374,\n",
       " 375,\n",
       " 377,\n",
       " 378,\n",
       " 380,\n",
       " 386,\n",
       " 387,\n",
       " 389,\n",
       " 391,\n",
       " 393,\n",
       " 417,\n",
       " 418,\n",
       " 420,\n",
       " 421,\n",
       " 423,\n",
       " 424,\n",
       " 426,\n",
       " 427,\n",
       " 429,\n",
       " 430,\n",
       " 432,\n",
       " 433,\n",
       " 435,\n",
       " 436,\n",
       " 438,\n",
       " 440,\n",
       " 442,\n",
       " 445,\n",
       " 446,\n",
       " 448,\n",
       " 451,\n",
       " 452,\n",
       " 454,\n",
       " 455,\n",
       " 457,\n",
       " 458,\n",
       " 460,\n",
       " 461,\n",
       " 463,\n",
       " 464,\n",
       " 466,\n",
       " 478,\n",
       " 479,\n",
       " 481,\n",
       " 482,\n",
       " 484,\n",
       " 485,\n",
       " 487,\n",
       " 489,\n",
       " 491,\n",
       " 492,\n",
       " 494,\n",
       " 495,\n",
       " 497,\n",
       " 498,\n",
       " 500,\n",
       " 501,\n",
       " 503,\n",
       " 504,\n",
       " 506,\n",
       " 507,\n",
       " 509,\n",
       " 510,\n",
       " 512,\n",
       " 513,\n",
       " 515,\n",
       " 518,\n",
       " 519,\n",
       " 521,\n",
       " 522,\n",
       " 524,\n",
       " 525,\n",
       " 527,\n",
       " 528,\n",
       " 530,\n",
       " 531,\n",
       " 533,\n",
       " 534,\n",
       " 536,\n",
       " 538,\n",
       " 540,\n",
       " 541,\n",
       " 543,\n",
       " 544,\n",
       " 546,\n",
       " 547,\n",
       " 549,\n",
       " 552,\n",
       " 564,\n",
       " 567,\n",
       " 570,\n",
       " 571,\n",
       " 573,\n",
       " 574,\n",
       " 576,\n",
       " 577,\n",
       " 579,\n",
       " 580,\n",
       " 582,\n",
       " 583,\n",
       " 585,\n",
       " 587,\n",
       " 589,\n",
       " 590,\n",
       " 592,\n",
       " 595,\n",
       " 596,\n",
       " 598,\n",
       " 599,\n",
       " 601,\n",
       " 604,\n",
       " 605,\n",
       " 607,\n",
       " 608,\n",
       " 610,\n",
       " 611,\n",
       " 613,\n",
       " 614,\n",
       " 616,\n",
       " 619,\n",
       " 620,\n",
       " 622,\n",
       " 623,\n",
       " 625,\n",
       " 626,\n",
       " 628,\n",
       " 629,\n",
       " 631,\n",
       " 632,\n",
       " 634,\n",
       " 636,\n",
       " 638,\n",
       " 639,\n",
       " 641,\n",
       " 642,\n",
       " 644,\n",
       " 645,\n",
       " 647,\n",
       " 648,\n",
       " 650,\n",
       " 651,\n",
       " 653,\n",
       " 654,\n",
       " 656,\n",
       " 662,\n",
       " 674,\n",
       " 675,\n",
       " 677,\n",
       " 678,\n",
       " 680,\n",
       " 681,\n",
       " 683,\n",
       " 685,\n",
       " 687,\n",
       " 688,\n",
       " 690,\n",
       " 691,\n",
       " 693,\n",
       " 694,\n",
       " 696,\n",
       " 697,\n",
       " 699,\n",
       " 711,\n",
       " 736,\n",
       " 748,\n",
       " 754,\n",
       " 755,\n",
       " 757,\n",
       " 759,\n",
       " 761,\n",
       " 786,\n",
       " 982,\n",
       " 1080,\n",
       " 1081,\n",
       " 1083,\n",
       " 1084,\n",
       " 1086,\n",
       " 1087,\n",
       " 1089,\n",
       " 1090,\n",
       " 1092,\n",
       " 1095,\n",
       " 1096,\n",
       " 1098,\n",
       " 1101,\n",
       " 1102,\n",
       " 1104,\n",
       " 1105,\n",
       " 1107,\n",
       " 1108,\n",
       " 1110,\n",
       " 1111,\n",
       " 1113,\n",
       " 1114,\n",
       " 1116,\n",
       " 1117,\n",
       " 1119,\n",
       " 1120,\n",
       " 1122,\n",
       " 1123,\n",
       " 1125,\n",
       " 1129,\n",
       " 1130,\n",
       " 1132,\n",
       " 1133,\n",
       " 1135,\n",
       " 1136,\n",
       " 1138,\n",
       " 1139,\n",
       " 1141,\n",
       " 1142,\n",
       " 1144,\n",
       " 1145,\n",
       " 1147,\n",
       " 1148,\n",
       " 1150,\n",
       " 1152,\n",
       " 1154,\n",
       " 1155,\n",
       " 1157,\n",
       " 1158,\n",
       " 1160,\n",
       " 1161,\n",
       " 1163,\n",
       " 1164,\n",
       " 1166,\n",
       " 1179,\n",
       " 1180,\n",
       " 1182,\n",
       " 1183,\n",
       " 1185,\n",
       " 1186,\n",
       " 1188,\n",
       " 1189,\n",
       " 1191,\n",
       " 1192,\n",
       " 1194,\n",
       " 1195,\n",
       " 1197,\n",
       " 1198,\n",
       " 1200,\n",
       " 1203,\n",
       " 1204,\n",
       " 1206,\n",
       " 1207,\n",
       " 1209,\n",
       " 1210,\n",
       " 1212,\n",
       " 1213,\n",
       " 1215,\n",
       " 1218,\n",
       " 1219,\n",
       " 1221,\n",
       " 1222,\n",
       " 1224,\n",
       " 1226,\n",
       " 1228,\n",
       " 1231,\n",
       " 1232,\n",
       " 1234,\n",
       " 1235,\n",
       " 1237,\n",
       " 1240,\n",
       " 1243,\n",
       " 1244,\n",
       " 1246,\n",
       " 1247,\n",
       " 1249,\n",
       " 1250,\n",
       " 1252,\n",
       " 1253,\n",
       " 1255,\n",
       " 1258,\n",
       " 1264,\n",
       " 1265,\n",
       " 1267,\n",
       " 1268,\n",
       " 1270,\n",
       " 1271,\n",
       " 1273,\n",
       " 1275,\n",
       " 1277,\n",
       " 1326,\n",
       " 1350,\n",
       " 1362,\n",
       " 1365,\n",
       " 1368,\n",
       " 1369,\n",
       " 1371,\n",
       " 1373,\n",
       " 1375,\n",
       " 1378,\n",
       " 1379,\n",
       " 1381,\n",
       " 1382,\n",
       " 1384,\n",
       " 1385,\n",
       " 1387,\n",
       " 1399,\n",
       " 1400,\n",
       " 1402,\n",
       " 1403,\n",
       " 1405,\n",
       " 1406,\n",
       " 1408,\n",
       " 1409,\n",
       " 1411,\n",
       " 1424,\n",
       " 1473,\n",
       " 1476,\n",
       " 1479,\n",
       " 1485,\n",
       " 1497,\n",
       " 1503,\n",
       " 1509,\n",
       " 1515,\n",
       " 1522,\n",
       " 1523,\n",
       " 1525,\n",
       " 1526,\n",
       " 1528,\n",
       " 1529,\n",
       " 1531,\n",
       " 1534,\n",
       " 1535,\n",
       " 1537,\n",
       " 1538,\n",
       " 1540,\n",
       " 1541,\n",
       " 1543,\n",
       " 1545,\n",
       " 1547,\n",
       " 1553,\n",
       " 1559,\n",
       " 1565,\n",
       " 1566,\n",
       " 1568,\n",
       " 1570,\n",
       " 1572,\n",
       " 1621,\n",
       " 1633,\n",
       " 1639,\n",
       " 1640,\n",
       " 1642,\n",
       " 1643,\n",
       " 1645,\n",
       " 1657,\n",
       " 1663,\n",
       " 1664,\n",
       " 1666,\n",
       " 1670,\n",
       " 1694,\n",
       " 1706,\n",
       " 1712,\n",
       " 1713,\n",
       " 1715,\n",
       " 1719,\n",
       " 1725,\n",
       " 1726,\n",
       " 1728,\n",
       " 1729,\n",
       " 1731,\n",
       " 1732,\n",
       " 1734,\n",
       " 1735,\n",
       " 1737,\n",
       " 1738,\n",
       " 1740,\n",
       " 1741,\n",
       " 1743,\n",
       " 1744,\n",
       " 1746,\n",
       " 1747,\n",
       " 1749,\n",
       " 1750,\n",
       " 1752,\n",
       " 1753,\n",
       " 1755,\n",
       " 1756,\n",
       " 1758,\n",
       " 1759,\n",
       " 1761,\n",
       " 1762,\n",
       " 1764,\n",
       " 1766,\n",
       " 1768,\n",
       " 1769,\n",
       " 1771,\n",
       " 1772,\n",
       " 1774,\n",
       " 1775,\n",
       " 1777,\n",
       " 1778,\n",
       " 1780,\n",
       " 1781,\n",
       " 1783,\n",
       " 1784,\n",
       " 1786,\n",
       " 1787,\n",
       " 1789,\n",
       " 1790,\n",
       " 1792,\n",
       " 1793,\n",
       " 1795,\n",
       " 1796,\n",
       " 1798,\n",
       " 1801,\n",
       " 1802,\n",
       " 1804,\n",
       " 1805,\n",
       " 1807,\n",
       " 1808,\n",
       " 1810,\n",
       " 1811,\n",
       " 1813,\n",
       " 1815,\n",
       " 1817,\n",
       " 1823,\n",
       " 1824,\n",
       " 1826,\n",
       " 1827,\n",
       " 1829,\n",
       " 1830,\n",
       " 1832,\n",
       " 1833,\n",
       " 1835,\n",
       " 1836,\n",
       " 1838,\n",
       " 1839,\n",
       " 1841,\n",
       " 1842,\n",
       " 1844,\n",
       " 1845,\n",
       " 1847,\n",
       " 1848,\n",
       " 1850,\n",
       " 1851,\n",
       " 1853,\n",
       " 1854,\n",
       " 1856,\n",
       " 1857,\n",
       " 1859,\n",
       " 1860,\n",
       " 1862,\n",
       " 1864,\n",
       " 1866,\n",
       " 1867,\n",
       " 1869,\n",
       " 1870,\n",
       " 1872,\n",
       " 1873,\n",
       " 1875,\n",
       " 1876,\n",
       " 1878,\n",
       " 1879,\n",
       " 1881,\n",
       " 1882,\n",
       " 1884,\n",
       " 1885,\n",
       " 1887,\n",
       " 1890,\n",
       " 1891,\n",
       " 1893,\n",
       " 1894,\n",
       " 1896,\n",
       " 1897,\n",
       " 1899,\n",
       " 1900,\n",
       " 1902,\n",
       " 1903,\n",
       " 1905,\n",
       " 1906,\n",
       " 1908,\n",
       " 1909,\n",
       " 1911,\n",
       " 1913,\n",
       " 1915,\n",
       " 1916,\n",
       " 1918,\n",
       " 1919,\n",
       " 1921,\n",
       " 1922,\n",
       " 1924,\n",
       " 1927,\n",
       " 1928,\n",
       " 1930,\n",
       " 1931,\n",
       " 1933,\n",
       " 1934,\n",
       " 1936,\n",
       " 1940,\n",
       " 1952,\n",
       " 1953,\n",
       " 1955,\n",
       " 1956,\n",
       " 1958,\n",
       " 1959,\n",
       " 1961,\n",
       " 1963,\n",
       " 1965,\n",
       " 2358,\n",
       " 2554,\n",
       " 2751,\n",
       " 2763,\n",
       " 2764,\n",
       " 2766,\n",
       " 2767,\n",
       " 2769,\n",
       " 2770,\n",
       " 2772,\n",
       " 2773,\n",
       " 2775,\n",
       " 2781,\n",
       " 2782,\n",
       " 2784,\n",
       " 2785,\n",
       " 2787,\n",
       " 2788,\n",
       " 2790,\n",
       " 2791,\n",
       " 2793,\n",
       " 2800,\n",
       " 2803,\n",
       " 2804,\n",
       " 2806,\n",
       " 2809,\n",
       " 2810,\n",
       " 2812,\n",
       " 2824,\n",
       " 2825,\n",
       " 2827,\n",
       " 2828,\n",
       " 2830,\n",
       " 2831,\n",
       " 2833,\n",
       " 2834,\n",
       " 2836,\n",
       " 2837,\n",
       " 2839,\n",
       " 2840,\n",
       " 2842,\n",
       " 2843,\n",
       " 2845,\n",
       " 2847,\n",
       " 2849,\n",
       " 2850,\n",
       " 2852,\n",
       " 2853,\n",
       " 2855,\n",
       " 2856,\n",
       " 2858,\n",
       " 2859,\n",
       " 2861,\n",
       " 2862,\n",
       " 2864,\n",
       " 2865,\n",
       " 2867,\n",
       " 2868,\n",
       " 2870,\n",
       " 2871,\n",
       " 2873,\n",
       " 2874,\n",
       " 2876,\n",
       " 2877,\n",
       " 2879,\n",
       " 2880,\n",
       " 2882,\n",
       " 2883,\n",
       " 2885,\n",
       " 2886,\n",
       " 2888,\n",
       " 2889,\n",
       " 2891,\n",
       " 2892,\n",
       " 2894,\n",
       " 2896,\n",
       " 2898,\n",
       " 2899,\n",
       " 2901,\n",
       " 2902,\n",
       " 2904,\n",
       " 2907,\n",
       " 2908,\n",
       " 2910,\n",
       " 2911,\n",
       " 2913,\n",
       " 2914,\n",
       " 2916,\n",
       " 2919,\n",
       " 2920,\n",
       " 2922,\n",
       " 2923,\n",
       " 2925,\n",
       " 2926,\n",
       " 2928,\n",
       " 2931,\n",
       " 2932,\n",
       " 2934,\n",
       " 2935,\n",
       " 2937,\n",
       " 2938,\n",
       " 2940,\n",
       " 2941,\n",
       " 2943,\n",
       " 2945,\n",
       " 2947,\n",
       " 3144,\n",
       " 4716,\n",
       " 4912,\n",
       " 4913,\n",
       " 4915,\n",
       " 4916,\n",
       " 4918,\n",
       " 4919,\n",
       " 4921,\n",
       " 4922,\n",
       " 4924,\n",
       " 4930,\n",
       " 4931,\n",
       " 4933,\n",
       " 4934,\n",
       " 4936,\n",
       " 4961,\n",
       " 4962,\n",
       " 4964,\n",
       " 4965,\n",
       " 4967,\n",
       " 4968,\n",
       " 4970,\n",
       " 4971,\n",
       " 4973,\n",
       " 4974,\n",
       " 4976,\n",
       " 4977,\n",
       " 4979,\n",
       " 4980,\n",
       " 4982,\n",
       " 4983,\n",
       " 4985,\n",
       " 4986,\n",
       " 4988,\n",
       " 4991,\n",
       " 4992,\n",
       " 4994,\n",
       " 4995,\n",
       " 4997,\n",
       " 4998,\n",
       " 5000,\n",
       " 5001,\n",
       " 5003,\n",
       " 5004,\n",
       " 5006,\n",
       " 5008,\n",
       " 5010,\n",
       " 5022,\n",
       " 5023,\n",
       " 5025,\n",
       " 5026,\n",
       " 5028,\n",
       " 5029,\n",
       " 5031,\n",
       " 5032,\n",
       " 5034,\n",
       " 5035,\n",
       " 5037,\n",
       " 5038,\n",
       " 5040,\n",
       " 5041,\n",
       " 5043,\n",
       " 5044,\n",
       " 5046,\n",
       " 5047,\n",
       " 5049,\n",
       " 5050,\n",
       " 5052,\n",
       " 5055,\n",
       " 5057,\n",
       " 5059,\n",
       " 5071,\n",
       " 5084,\n",
       " 5085,\n",
       " 5087,\n",
       " 5090,\n",
       " 5091,\n",
       " 5093,\n",
       " 5094,\n",
       " 5096,\n",
       " 5109,\n",
       " 5112,\n",
       " 5115,\n",
       " 5116,\n",
       " 5118,\n",
       " 5119,\n",
       " 5121,\n",
       " 5122,\n",
       " 5124,\n",
       " 5125,\n",
       " 5127,\n",
       " 5128,\n",
       " 5130,\n",
       " 5133,\n",
       " 5145,\n",
       " 5146,\n",
       " 5148,\n",
       " 5149,\n",
       " 5151,\n",
       " 5154,\n",
       " 5156,\n",
       " 5158,\n",
       " 5161,\n",
       " 5162,\n",
       " 5164,\n",
       " 5165,\n",
       " 5167,\n",
       " 5168,\n",
       " 5170,\n",
       " 5182,\n",
       " 5207,\n",
       " 5305,\n",
       " 5354,\n",
       " 5357,\n",
       " 5358,\n",
       " 5360,\n",
       " 5361,\n",
       " 5363,\n",
       " 5364,\n",
       " 5366,\n",
       " 5369,\n",
       " 5370,\n",
       " 5372,\n",
       " 5373,\n",
       " 5375,\n",
       " 5376,\n",
       " 5378,\n",
       " 5403,\n",
       " 5404,\n",
       " 5406,\n",
       " 5407,\n",
       " 5409,\n",
       " 5410,\n",
       " 5412,\n",
       " 5413,\n",
       " 5415,\n",
       " 5418,\n",
       " 5419,\n",
       " 5421,\n",
       " 5422,\n",
       " 5424,\n",
       " 5425,\n",
       " 5427,\n",
       " 5439,\n",
       " 5440,\n",
       " 5442,\n",
       " 5443,\n",
       " 5445,\n",
       " 5448,\n",
       " 5450,\n",
       " 5452,\n",
       " 5453,\n",
       " 5455,\n",
       " 5458,\n",
       " 5459,\n",
       " 5461,\n",
       " ...]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive-time-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
